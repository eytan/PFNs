{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528209127,
    "executionStopTime": 1743528217022,
    "language": "python",
    "originalKey": "a4c56e12-55d0-4b3e-a2dd-bec3739a135a",
    "outputsInitialized": true,
    "requestMsgId": "61357428-9500-4edb-8e7d-2a6608607fae",
    "serverExecutionDuration": 6.2562888488173,
    "showInput": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from botorch.test_functions.synthetic import SyntheticTestFunction\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class WingWeightMultiFidelity(SyntheticTestFunction):\n",
    "    \"\"\"Wing Weight Design Problem from [Chen2024]_.\n",
    "\n",
    "    Design variables (physical units):\n",
    "      1. s_w   in [150,   200]   (wing area)\n",
    "      2. w_fw  in [220,   300]   (fuel weight)\n",
    "      3. A     in [6,     10]    (aspect ratio)\n",
    "      4. Lambda_deg in [-10, 10]  (sweep angle, degrees)\n",
    "      5. q     in [16,    45]    (dynamic pressure)\n",
    "      6. lam   in [0.5,   1.0]   (taper ratio)\n",
    "      7. t_c   in [0.08,  0.18]   (thickness-to-chord)\n",
    "      8. N_z   in [2.5,   6.0]    (ultimate load factor)\n",
    "      9. w_dg  in [1700,  2500]   (design gross weight)\n",
    "      10. w_pp in [0.025, 0.08]    (weight per unit area)\n",
    "\n",
    "    Fidelity parameter (stored as the 11th input):\n",
    "      0: High fidelity (HF)\n",
    "      1: Low fidelity 1 (LF1)\n",
    "      2: Low fidelity 2 (LF2)\n",
    "      3: Low fidelity 3 (LF2)\n",
    "\n",
    "    The HF model is given by:\n",
    "      f0 = 0.036 * s_w^0.758 * w_fw^0.0035 * (A/(cos^2(Lambda_rad)))^0.6 *\n",
    "           q^0.006 * lam^0.04 * (100*t_c/cos(Lambda_rad))^-0.3 *\n",
    "           (N_z*w_dg)^0.49 + s_w*w_pp\n",
    "\n",
    "    LF models use slightly altered exponents and additive biases.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = 11\n",
    "    _num_fidelities = 1\n",
    "    _bounds = [\n",
    "        (150.0, 200.0),  # s_w\n",
    "        (220.0, 300.0),  # w_fw\n",
    "        (6.0, 10.0),  # A\n",
    "        (-10.0, 10.0),  # Lambda_deg\n",
    "        (16.0, 45.0),  # q\n",
    "        (0.5, 1.0),  # lam\n",
    "        (0.08, 0.18),  # t_c\n",
    "        (2.5, 6.0),  # N_z\n",
    "        (1700.0, 2500.0),  # w_dg\n",
    "        (0.025, 0.08),  # w_pp\n",
    "        (0, 3),\n",
    "    ]\n",
    "    fidelities = [0, 1, 2, 3]\n",
    "    _optimal_value = 123.25\n",
    "\n",
    "    def evaluate_true(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        # Expect X of shape [..., 11]: first 10 are design variables, last is fidelity index.\n",
    "        s_w = X[..., 0]\n",
    "        w_fw = X[..., 1]\n",
    "        A = X[..., 2]\n",
    "        Lambda_deg = X[..., 3]\n",
    "        Lambda_rad = Lambda_deg * math.pi / 180.0\n",
    "\n",
    "        q = X[..., 4]\n",
    "        lam = X[..., 5]\n",
    "        t_c = X[..., 6]\n",
    "        N_z = X[..., 7]\n",
    "        w_dg = X[..., 8]\n",
    "        w_pp = X[..., 9]\n",
    "        fidelity = X[..., 10]\n",
    "        cos_val = torch.cos(Lambda_rad)\n",
    "        y = torch.zeros_like(s_w)\n",
    "        # High fidelity (fidelity == 0)\n",
    "        mask = fidelity == 0\n",
    "        if mask.any():\n",
    "            hf = (\n",
    "                0.036\n",
    "                * (s_w**0.758)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + s_w * w_pp\n",
    "            )\n",
    "            y[mask] = hf[mask]\n",
    "        # Low fidelity 1 (fidelity == 1)\n",
    "        mask = fidelity == 1\n",
    "        if mask.any():\n",
    "            lf1 = (\n",
    "                0.036\n",
    "                * (s_w**0.758)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + w_pp\n",
    "            )\n",
    "            y[mask] = lf1[mask]\n",
    "        # Low fidelity 2 (fidelity == 2)\n",
    "        mask = fidelity == 2\n",
    "        if mask.any():\n",
    "            lf2 = (\n",
    "                0.036\n",
    "                * (s_w**0.8)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + w_pp\n",
    "            )\n",
    "            y[mask] = lf2[mask]\n",
    "        # Low fidelity 3 (fidelity == 3)\n",
    "        mask = fidelity == 3\n",
    "        if mask.any():\n",
    "            lf3 = (\n",
    "                0.036\n",
    "                * (s_w**0.9)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "            )\n",
    "            y[mask] = lf3[mask]\n",
    "        return y\n",
    "\n",
    "    def cost(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        fidelity = X[..., 10]\n",
    "        c = torch.zeros_like(fidelity)\n",
    "        c[fidelity == 0] = 1000.0\n",
    "        c[fidelity == 1] = 100.0\n",
    "        c[fidelity == 2] = 10.0\n",
    "        c[fidelity == 3] = 1.0\n",
    "        return c\n",
    "\n",
    "\n",
    "class BoreholeMultiFidelity(SyntheticTestFunction):\n",
    "    \"\"\"Borehole Problem from [Chen2024]_.\n",
    "\n",
    "    This problem models water flow through a borehole with 8 design variables:\n",
    "          1. r_w   in [0.05,   0.15]   (borehole radius)\n",
    "          2. r     in [100,    50000]  (radius of influence)\n",
    "          3. T_u   in [63070,  115600] (transmissivity of upper aquifer)\n",
    "          4. T_l   in [63.1,   116]    (transmissivity of lower aquifer)\n",
    "          5. H_u   in [990,    1110]   (potentiometric head of upper aquifer)\n",
    "          6. H_l   in [700,    820]    (potentiometric head of lower aquifer)\n",
    "          7. L     in [1120,   1680]   (length of borehole)\n",
    "          8. K_w   in [9855,   12045]  (hydraulic conductivity)\n",
    "\n",
    "        The fidelity index (9th input) is categorical:\n",
    "          0: High fidelity (HF)\n",
    "          1: Low fidelity 1 (LF1)\n",
    "          2: Low fidelity 2 (LF2)\n",
    "          3: Low fidelity 3 (LF3)\n",
    "          4: Low fidelity 4 (LF4)\n",
    "\n",
    "        The HF model is defined by:\n",
    "          f0 = (2*pi*T_u*(H_u-H_l)) / [ ln(r/r_w) * (1 + (2*L*T_l)/(ln(r/r_w)*r_w^2*K_w)) ]\n",
    "\n",
    "        The low-fidelity models modify exponents and add a bias.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = 9\n",
    "    _num_fidelities = 1\n",
    "    _bounds = [\n",
    "        (0.05, 0.15),  # r_w\n",
    "        (100.0, 10000.0),  # r\n",
    "        (100.0, 1000.0),  # T_u\n",
    "        (10.0, 500.0),  # T_l\n",
    "        (990.0, 1110.0),  # H_u\n",
    "        (700.0, 820.0),  # H_l\n",
    "        (1000.0, 2000.0),  # L\n",
    "        (6000.0, 12000.0),  # K_w\n",
    "        (0, 4),  # fidelity\n",
    "    ]\n",
    "    fidelities = [0, 1, 2, 3, 4]\n",
    "    _optimal_value = 3.98\n",
    "\n",
    "    def evaluate_true(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        r_w = X[..., 0]\n",
    "        r = X[..., 1]\n",
    "        T_u = X[..., 2]\n",
    "        T_l = X[..., 3]\n",
    "        H_u = X[..., 4]\n",
    "        H_l = X[..., 5]\n",
    "        L = X[..., 6]\n",
    "        K_w = X[..., 7]\n",
    "        fidelity = X[..., 8]\n",
    "\n",
    "        log_term = torch.log(r / r_w)\n",
    "        numer = 2.0 * math.pi * T_u * (H_u - H_l)\n",
    "        y = torch.zeros_like(r_w)\n",
    "\n",
    "        # HF (fidelity 0)\n",
    "        mask = fidelity == 0\n",
    "        if mask.any():\n",
    "            hf_denom = log_term * (\n",
    "                1.0 + (2.0 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            hf = numer / hf_denom\n",
    "            y[mask] = hf[mask]\n",
    "\n",
    "        # LF1 (fidelity 1): add bias.\n",
    "        mask = fidelity == 1\n",
    "        if mask.any():\n",
    "            lf1_numer = 2.0 * math.pi * T_u * (H_u - 0.8 * H_l)\n",
    "            lf1_denom = log_term * (\n",
    "                1.0 + (L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf1 = lf1_numer / lf1_denom\n",
    "            y[mask] = lf1[mask]\n",
    "\n",
    "        # LF2 (fidelity 2): modify the exponent on log_term and add bias.\n",
    "        mask = fidelity == 2\n",
    "        if mask.any():\n",
    "            lf2_denom = log_term * (\n",
    "                1.0 + (8 * L * T_u) / (log_term * (r_w**2) * K_w) + 0.75 * T_u / T_l\n",
    "            )\n",
    "            lf2 = numer / lf2_denom\n",
    "            y[mask] = lf2[mask]\n",
    "\n",
    "        # LF3 (fidelity 3): modify r_w exponent slightly.\n",
    "        mask = fidelity == 3\n",
    "        if mask.any():\n",
    "            lf3_log_term = torch.log(4 * r / r_w)\n",
    "            lf3_numer = 2.0 * math.pi * T_u * (1.09 * H_u - H_l)\n",
    "            lf3_denom = lf3_log_term * (\n",
    "                1.0 + (3 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf3 = lf3_numer / lf3_denom\n",
    "            y[mask] = lf3[mask]\n",
    "        # LF4 (fidelity 4): further bias.\n",
    "        mask = fidelity == 4\n",
    "        if mask.any():\n",
    "            lf4_log_term = torch.log(2 * r / r_w)\n",
    "            lf4_numer = 2.0 * math.pi * T_u * (1.05 * H_u - H_l)\n",
    "            lf4_denom = lf4_log_term * (\n",
    "                1.0 + (3 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf4 = lf4_numer / lf4_denom\n",
    "            y[mask] = lf4[mask]\n",
    "\n",
    "        return y\n",
    "\n",
    "    def cost(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        fidelity = X[..., 8]\n",
    "        c = torch.zeros_like(fidelity)\n",
    "        c[fidelity == 0] = 1000.0\n",
    "        c[fidelity == 1] = 100.0\n",
    "        c[fidelity == 2] = 10.0\n",
    "        c[fidelity == 3] = 100.0\n",
    "        c[fidelity == 4] = 10.0\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WingWeightMultiFidelitySmall(SyntheticTestFunction):\n",
    "    \"\"\"Wing Weight Design Problem from [Chen2024]_.\n",
    "\n",
    "    Design variables (physical units):\n",
    "      1. s_w   in [150,   200]   (wing area)\n",
    "      2. w_fw  in [220,   300]   (fuel weight)\n",
    "      3. A     in [6,     10]    (aspect ratio)\n",
    "      4. Lambda_deg in [-10, 10]  (sweep angle, degrees)\n",
    "      5. q     in [16,    45]    (dynamic pressure)\n",
    "      6. lam   in [0.5,   1.0]   (taper ratio)\n",
    "      7. t_c   in [0.08,  0.18]   (thickness-to-chord)\n",
    "      8. N_z   in [2.5,   6.0]    (ultimate load factor)\n",
    "      9. w_dg  in [1700,  2500]   (design gross weight)\n",
    "      10. w_pp in [0.025, 0.08]    (weight per unit area)\n",
    "\n",
    "    Fidelity parameter (stored as the 11th input):\n",
    "      0: High fidelity (HF)\n",
    "      1: Low fidelity 1 (LF1)\n",
    "      2: Low fidelity 2 (LF2)\n",
    "      3: Low fidelity 3 (LF2)\n",
    "\n",
    "    The HF model is given by:\n",
    "      f0 = 0.036 * s_w^0.758 * w_fw^0.0035 * (A/(cos^2(Lambda_rad)))^0.6 *\n",
    "           q^0.006 * lam^0.04 * (100*t_c/cos(Lambda_rad))^-0.3 *\n",
    "           (N_z*w_dg)^0.49 + s_w*w_pp\n",
    "\n",
    "    LF models use slightly altered exponents and additive biases.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = 6\n",
    "    _num_fidelities = 1\n",
    "    _bounds = [\n",
    "        (150.0, 200.0),  # s_w\n",
    "        (220.0, 300.0),  # w_fw\n",
    "        (6.0, 10.0),  # A\n",
    "        (-10.0, 10.0),  # Lambda_deg\n",
    "        (16.0, 45.0),  # q\n",
    "        (0.5, 1.0),  # lam\n",
    "        # (0.08, 0.18),  # t_c\n",
    "        # (2.5, 6.0),  # N_z\n",
    "        # (1700.0, 2500.0),  # w_dg\n",
    "        # (0.025, 0.08),  # w_pp\n",
    "        (0, 3), # fidelity\n",
    "    ]\n",
    "    fidelities = [0, 1, 2, 3]\n",
    "    _optimal_value = 123.25\n",
    "\n",
    "    def evaluate_true(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        # Expect X of shape [..., 11]: first 10 are design variables, last is fidelity index.\n",
    "        s_w = X[..., 0]\n",
    "        w_fw = X[..., 1]\n",
    "        A = X[..., 2]\n",
    "        Lambda_deg = X[..., 3]\n",
    "        Lambda_rad = Lambda_deg * math.pi / 180.0\n",
    "\n",
    "        q = X[..., 4]\n",
    "        lam = X[..., 5]\n",
    "        t_c = 0.13 #X[..., 6]\n",
    "        N_z = 4.5 #X[..., 7]\n",
    "        w_dg = 2000 #X[..., 8]\n",
    "        w_pp = 0.05 #X[..., 9]\n",
    "        fidelity = X[..., -1]\n",
    "        cos_val = torch.cos(Lambda_rad)\n",
    "        y = torch.zeros_like(s_w)\n",
    "        # High fidelity (fidelity == 0)\n",
    "        mask = fidelity == 0\n",
    "        if mask.any():\n",
    "            hf = (\n",
    "                0.036\n",
    "                * (s_w**0.758)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + s_w * w_pp\n",
    "            )\n",
    "            y[mask] = hf[mask]\n",
    "        # Low fidelity 1 (fidelity == 1)\n",
    "        mask = fidelity == 1\n",
    "        if mask.any():\n",
    "            lf1 = (\n",
    "                0.036\n",
    "                * (s_w**0.758)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + w_pp\n",
    "            )\n",
    "            y[mask] = lf1[mask]\n",
    "        # Low fidelity 2 (fidelity == 2)\n",
    "        mask = fidelity == 2\n",
    "        if mask.any():\n",
    "            lf2 = (\n",
    "                0.036\n",
    "                * (s_w**0.8)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "                + w_pp\n",
    "            )\n",
    "            y[mask] = lf2[mask]\n",
    "        # Low fidelity 3 (fidelity == 3)\n",
    "        mask = fidelity == 3\n",
    "        if mask.any():\n",
    "            lf3 = (\n",
    "                0.036\n",
    "                * (s_w**0.9)\n",
    "                * (w_fw**0.0035)\n",
    "                * ((A / (cos_val**2)) ** 0.6)\n",
    "                * (q**0.006)\n",
    "                * (lam**0.04)\n",
    "                * ((100.0 * t_c / cos_val) ** (-0.3))\n",
    "                * ((N_z * w_dg) ** 0.49)\n",
    "            )\n",
    "            y[mask] = lf3[mask]\n",
    "        return y\n",
    "\n",
    "    def cost(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        fidelity = X[..., 10]\n",
    "        c = torch.zeros_like(fidelity)\n",
    "        c[fidelity == 0] = 1000.0\n",
    "        c[fidelity == 1] = 100.0\n",
    "        c[fidelity == 2] = 10.0\n",
    "        c[fidelity == 3] = 1.0\n",
    "        return c\n",
    "\n",
    "\n",
    "class BoreholeMultiFidelitySmall(SyntheticTestFunction):\n",
    "    \"\"\"Borehole Problem from [Chen2024]_.\n",
    "\n",
    "    This problem models water flow through a borehole with 8 design variables:\n",
    "          1. r_w   in [0.05,   0.15]   (borehole radius)\n",
    "          2. r     in [100,    50000]  (radius of influence)\n",
    "          3. T_u   in [63070,  115600] (transmissivity of upper aquifer)\n",
    "          4. T_l   in [63.1,   116]    (transmissivity of lower aquifer)\n",
    "          5. H_u   in [990,    1110]   (potentiometric head of upper aquifer)\n",
    "          6. H_l   in [700,    820]    (potentiometric head of lower aquifer)\n",
    "          7. L     in [1120,   1680]   (length of borehole)\n",
    "          8. K_w   in [9855,   12045]  (hydraulic conductivity)\n",
    "\n",
    "        The fidelity index (9th input) is categorical:\n",
    "          0: High fidelity (HF)\n",
    "          1: Low fidelity 1 (LF1)\n",
    "          2: Low fidelity 2 (LF2)\n",
    "          3: Low fidelity 3 (LF3)\n",
    "          4: Low fidelity 4 (LF4)\n",
    "\n",
    "        The HF model is defined by:\n",
    "          f0 = (2*pi*T_u*(H_u-H_l)) / [ ln(r/r_w) * (1 + (2*L*T_l)/(ln(r/r_w)*r_w^2*K_w)) ]\n",
    "\n",
    "        The low-fidelity models modify exponents and add a bias.\n",
    "    \"\"\"\n",
    "\n",
    "    dim = 7\n",
    "    _num_fidelities = 1\n",
    "    _bounds = [\n",
    "        (0.05, 0.15),  # r_w\n",
    "        (100.0, 10000.0),  # r\n",
    "        (100.0, 1000.0),  # T_u\n",
    "        (10.0, 500.0),  # T_l\n",
    "        (990.0, 1110.0),  # H_u\n",
    "        # (700.0, 820.0),  # H_l\n",
    "        # (1000.0, 2000.0),  # L\n",
    "        # (6000.0, 12000.0),  # K_w\n",
    "        (0, 4),  # fidelity\n",
    "    ]\n",
    "    fidelities = [0, 1, 2, 3, 4]\n",
    "    _optimal_value = 3.98\n",
    "\n",
    "    def evaluate_true(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        r_w = X[..., 0]\n",
    "        r = X[..., 1]\n",
    "        T_u = X[..., 2]\n",
    "        T_l = X[..., 3]\n",
    "        H_u = X[..., 4]\n",
    "        H_l = X[..., 5]\n",
    "        L = 760 # X[..., 6]\n",
    "        K_w = 1500 #X[..., 7]\n",
    "        fidelity = 9000 #X[..., 8]\n",
    "\n",
    "        log_term = torch.log(r / r_w)\n",
    "        numer = 2.0 * math.pi * T_u * (H_u - H_l)\n",
    "        y = torch.zeros_like(r_w)\n",
    "\n",
    "        # HF (fidelity 0)\n",
    "        mask = fidelity == 0\n",
    "        if mask.any():\n",
    "            hf_denom = log_term * (\n",
    "                1.0 + (2.0 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            hf = numer / hf_denom\n",
    "            y[mask] = hf[mask]\n",
    "\n",
    "        # LF1 (fidelity 1): add bias.\n",
    "        mask = fidelity == 1\n",
    "        if mask.any():\n",
    "            lf1_numer = 2.0 * math.pi * T_u * (H_u - 0.8 * H_l)\n",
    "            lf1_denom = log_term * (\n",
    "                1.0 + (L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf1 = lf1_numer / lf1_denom\n",
    "            y[mask] = lf1[mask]\n",
    "\n",
    "        # LF2 (fidelity 2): modify the exponent on log_term and add bias.\n",
    "        mask = fidelity == 2\n",
    "        if mask.any():\n",
    "            lf2_denom = log_term * (\n",
    "                1.0 + (8 * L * T_u) / (log_term * (r_w**2) * K_w) + 0.75 * T_u / T_l\n",
    "            )\n",
    "            lf2 = numer / lf2_denom\n",
    "            y[mask] = lf2[mask]\n",
    "\n",
    "        # LF3 (fidelity 3): modify r_w exponent slightly.\n",
    "        mask = fidelity == 3\n",
    "        if mask.any():\n",
    "            lf3_log_term = torch.log(4 * r / r_w)\n",
    "            lf3_numer = 2.0 * math.pi * T_u * (1.09 * H_u - H_l)\n",
    "            lf3_denom = lf3_log_term * (\n",
    "                1.0 + (3 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf3 = lf3_numer / lf3_denom\n",
    "            y[mask] = lf3[mask]\n",
    "        # LF4 (fidelity 4): further bias.\n",
    "        mask = fidelity == 4\n",
    "        if mask.any():\n",
    "            lf4_log_term = torch.log(2 * r / r_w)\n",
    "            lf4_numer = 2.0 * math.pi * T_u * (1.05 * H_u - H_l)\n",
    "            lf4_denom = lf4_log_term * (\n",
    "                1.0 + (3 * L * T_u) / (log_term * (r_w**2) * K_w) + T_u / T_l\n",
    "            )\n",
    "            lf4 = lf4_numer / lf4_denom\n",
    "            y[mask] = lf4[mask]\n",
    "\n",
    "        return y\n",
    "\n",
    "    def cost(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        fidelity = X[..., 8]\n",
    "        c = torch.zeros_like(fidelity)\n",
    "        c[fidelity == 0] = 1000.0\n",
    "        c[fidelity == 1] = 100.0\n",
    "        c[fidelity == 2] = 10.0\n",
    "        c[fidelity == 3] = 100.0\n",
    "        c[fidelity == 4] = 10.0\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528318060,
    "executionStopTime": 1743528318381,
    "language": "python",
    "originalKey": "11f17363-b3c0-4b55-b211-436797c48a1e",
    "outputsInitialized": true,
    "requestMsgId": "961e03e5-ed26-47c2-8e06-8106aa186b53",
    "serverExecutionDuration": 1.8204906955361,
    "showInput": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from botorch.fit import fit_fully_bayesian_model_nuts, fit_gpytorch_mll\n",
    "from botorch.models.fully_bayesian_multitask import SaasFullyBayesianMultiTaskGP\n",
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "\n",
    "from botorch.models.multitask import MultiTaskGP\n",
    "\n",
    "from botorch.models.transforms.input import (\n",
    "    ChainedInputTransform,\n",
    "    # LatentCategoricalEmbedding,\n",
    "    # LatentCategoricalSpec,\n",
    "    Normalize,\n",
    ")\n",
    "from botorch.models.transforms.outcome import Standardize, StratifiedStandardize\n",
    "from botorch.utils.transforms import unnormalize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "tkwargs = {\"dtype\": torch.double}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528129775,
    "executionStopTime": 1743528132881,
    "language": "python",
    "originalKey": "e02d0748-e092-4001-b8f0-59666e0e7b29",
    "outputsInitialized": true,
    "requestMsgId": "f59e8b19-0f9f-4f93-b9ad-277685684230",
    "serverExecutionDuration": 1.955185085535,
    "showInput": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, test_X, test_Y):\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(test_X, observation_noise=True)\n",
    "        # compute sum of LL of each point in test set (using only marginal variances)\n",
    "        var = posterior.variance\n",
    "        mean = posterior.mean\n",
    "        nll = (\n",
    "            -Normal(loc=mean.squeeze(-1), scale=var.squeeze(-1))\n",
    "            .log_prob(test_Y.view(-1))\n",
    "            .sum(dim=-1)\n",
    "            .mean()  # take average over MCMC samples (if needed)\n",
    "            .item()\n",
    "        )\n",
    "        mse = (mean - test_Y).pow(2).mean().item()\n",
    "    return nll, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pfn_on_problem(pfn, problem, train_X, train_Y, test_X, test_Y):\n",
    "    task_id = train_X[:, -1].long()\n",
    "    train_X = train_X[:, :-1]\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        posterior = pfn_predict(pfn, task_id, train_X, train_Y, test_X[:, :-1])\n",
    "        # compute sum of LL of each point in test set (using only marginal variances)\n",
    "        var = posterior.variance\n",
    "        mean = posterior.mean\n",
    "        nll = (\n",
    "            -Normal(loc=mean.squeeze(-1), scale=var.squeeze(-1))\n",
    "            .log_prob(test_Y.view(-1))\n",
    "            .sum(dim=-1)\n",
    "            .mean()  # take average over MCMC samples (if needed)\n",
    "            .item()\n",
    "        )\n",
    "        mse = (mean - test_Y).pow(2).mean().item()\n",
    "    return nll, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a Transformer with 25.77 M parameters\n",
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "from utils import load_model, pfn_predict\n",
    "# pfn = load_model(\"/home/yl9959/mtpfn/final_models/revived-frog-499\")\n",
    "pfn = load_model(\"/home/yl9959/mtpfn/final_models/vibrant-breeze-498\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to create tensor with negative dimension -4: [170, 1, -4]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_pfn_on_problem(pfn, problem, train_X, train_Y, test_X, test_Y)\n",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m, in \u001b[0;36meval_pfn_on_problem\u001b[0;34m(pfn, problem, train_X, train_Y, test_X, test_Y)\u001b[0m\n\u001b[1;32m      3\u001b[0m train_X \u001b[38;5;241m=\u001b[39m train_X[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m     posterior \u001b[38;5;241m=\u001b[39m pfn_predict(pfn, task_id, train_X, train_Y, test_X[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# compute sum of LL of each point in test set (using only marginal variances)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     var \u001b[38;5;241m=\u001b[39m posterior\u001b[38;5;241m.\u001b[39mvariance\n",
      "File \u001b[0;32m~/mtpfn/utils.py:344\u001b[0m, in \u001b[0;36mpfn_predict\u001b[0;34m(pfn, task_id, train_x, train_y, possible_x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     pfn_model \u001b[38;5;241m=\u001b[39m pfn_gaussian_fit(pfn, task_id, train_x, train_y)\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pfn_model\u001b[38;5;241m.\u001b[39mposterior(possible_x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/mtpfn/utils.py:110\u001b[0m, in \u001b[0;36mPFNGaussian.posterior\u001b[0;34m(self, X, output_indices, observation_noise, posterior_transform)\u001b[0m\n\u001b[1;32m    108\u001b[0m original_shape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    109\u001b[0m X_reshape \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 110\u001b[0m pfn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpfn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_task_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_y, X_reshape, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    111\u001b[0m mean \u001b[38;5;241m=\u001b[39m pfn_outputs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    112\u001b[0m variance \u001b[38;5;241m=\u001b[39m pfn_outputs[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mexp()\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mtpfn/PFNs/pfns/transformer.py:457\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     style \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;66;03m# forward(style, x, y),  \"single_eval_pos\" corresponds to where test x starts\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward(\n\u001b[1;32m    458\u001b[0m         (style, x, y, task_id), single_eval_pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(args[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    459\u001b[0m     )\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# during training (x, y, task_id) is passed with single_eval_pos\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# case model((x,y,task_id), src_mask=None, single_eval_pos=None, only_return_standard_out=True)\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# case model((style,x,y,task_id), src_mask=None, single_eval_pos=None, only_return_standard_out=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/mtpfn/PFNs/pfns/transformer.py:497\u001b[0m, in \u001b[0;36mTransformerModel._forward\u001b[0;34m(self, src, src_mask, single_eval_pos, only_return_standard_out)\u001b[0m\n\u001b[1;32m    490\u001b[0m     onehot_task_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mone_hot(\n\u001b[1;32m    491\u001b[0m         task_id\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_tasks\n\u001b[1;32m    492\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(x_src)\n\u001b[1;32m    493\u001b[0m     x_src \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([onehot_task_ids, x_src], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 497\u001b[0m x_src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x_src)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxial\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_type:\n\u001b[1;32m    499\u001b[0m     N, D, B, E \u001b[38;5;241m=\u001b[39m x_src\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/pfn/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/mtpfn/PFNs/pfns/encoders.py:294\u001b[0m, in \u001b[0;36mVariableNumFeaturesEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    290\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m/\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    291\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    292\u001b[0m         (\n\u001b[1;32m    293\u001b[0m             x,\n\u001b[0;32m--> 294\u001b[0m             torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m    295\u001b[0m                 \u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    296\u001b[0m             ),\n\u001b[1;32m    297\u001b[0m         ),\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_encoder(x)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to create tensor with negative dimension -4: [170, 1, -4]"
     ]
    }
   ],
   "source": [
    "eval_pfn_on_problem(pfn, problem, train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528939339,
    "executionStopTime": 1743528940127,
    "language": "python",
    "originalKey": "a194f315-36d3-4980-9506-c01343153a81",
    "outputsInitialized": true,
    "requestMsgId": "dbaeb34d-8bc8-4943-891a-fae5a0fc7212",
    "serverExecutionDuration": 3.0471379868686,
    "showInput": true
   },
   "outputs": [],
   "source": [
    "def eval_models_on_problem(problem, train_X, train_Y, test_X, test_Y):\n",
    "    res = {}\n",
    "    # test STGP on target task\n",
    "    target_mask = train_X[:, -1] == 0\n",
    "    model = SingleTaskGP(\n",
    "        train_X[target_mask],\n",
    "        train_Y[target_mask],\n",
    "        input_transform=Normalize(\n",
    "            d=train_X.shape[-1], indices=list(range(train_X.shape[-1] - 1))\n",
    "        ),\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    _ = fit_gpytorch_mll(mll)\n",
    "    nll, mse = eval_model(model=model, test_X=test_X, test_Y=test_Y)\n",
    "    res[\"STGP - target only\"] = {\"NLL\": nll, \"MSE\": mse}\n",
    "\n",
    "    # Test MTGP with ICM\n",
    "    model = MultiTaskGP(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        input_transform=Normalize(\n",
    "            d=train_X.shape[-1], indices=list(range(train_X.shape[-1] - 1))\n",
    "        ),\n",
    "        outcome_transform=StratifiedStandardize(\n",
    "            stratification_idx=problem.dim - 1,\n",
    "            task_values=torch.tensor(problem.fidelities, dtype=torch.long),\n",
    "        ),\n",
    "        task_feature=problem.dim - 1,\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    _ = fit_gpytorch_mll(mll)\n",
    "    nll, mse = eval_model(model=model, test_X=test_X, test_Y=test_Y)\n",
    "    res[\"MTGP - ICM - MAP\"] = {\"NLL\": nll, \"MSE\": mse}\n",
    "    # Test Fully Bayesian MTGP with Latent Embeddings\n",
    "    model = SaasFullyBayesianMultiTaskGP(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        input_transform=Normalize(\n",
    "            d=train_X.shape[-1], indices=list(range(train_X.shape[-1] - 1))\n",
    "        ),\n",
    "        task_feature=problem.dim - 1,\n",
    "        outcome_transform=StratifiedStandardize(\n",
    "            stratification_idx=problem.dim - 1,\n",
    "            task_values=torch.tensor(problem.fidelities, dtype=torch.long),\n",
    "        ),\n",
    "    )\n",
    "    _ = fit_fully_bayesian_model_nuts(model, jit_compile=True)\n",
    "    nll, mse = eval_model(model=model, test_X=test_X, test_Y=test_Y)\n",
    "    res[\"MTGP - Latent Embeddings - FB\"] = {\"NLL\": nll, \"MSE\": mse}\n",
    "\n",
    "    # test LVGP with MAP estimation\n",
    "    d = train_X.shape[-1]\n",
    "    cat_dims = [problem.dim - 1]\n",
    "    # construct input transform\n",
    "    input_transform = ChainedInputTransform(\n",
    "        normalize=Normalize(d=d, indices=list(range(d - 1))),\n",
    "        # latent_emb=LatentCategoricalEmbedding(\n",
    "        #     [\n",
    "        #         LatentCategoricalSpec(\n",
    "        #             idx=i,\n",
    "        #             num_categories=len(problem.fidelities),\n",
    "        #             latent_dim=2,\n",
    "        #         )\n",
    "        #         for i in cat_dims\n",
    "        #     ],\n",
    "        #     dim=d,\n",
    "        # ).to(train_X),\n",
    "    )\n",
    "    model = SingleTaskGP(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        input_transform=input_transform,\n",
    "    )\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    _ = fit_gpytorch_mll(mll)\n",
    "    nll, mse = eval_model(model=model, test_X=test_X, test_Y=test_Y)\n",
    "    res[\"MTGP - Latent Embeddings - MAP\"] = {\"NLL\": nll, \"MSE\": mse}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "customInput": null,
    "language": "markdown",
    "originalKey": "1f8d148e-a0e7-4915-952f-7a405ec8a480",
    "showInput": false
   },
   "source": [
    "# Wing weight\n",
    "### Generate initial training set as in Chen et al 2024. Generate test set for target fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528960203,
    "executionStopTime": 1743529095209,
    "language": "python",
    "originalKey": "fd812914-49d4-4023-926e-2d41c4157ded",
    "outputsInitialized": true,
    "requestMsgId": "097e842b-186a-44f5-88c3-cd12b0240b33",
    "serverExecutionDuration": 5.1055490039289,
    "showInput": true
   },
   "outputs": [
    {
     "ename": "InputDataError",
     "evalue": "Expected the bounds to match the dimensionality of the domain. Got self.dim=6 and len(self._bounds)=7.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInputDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m problem \u001b[38;5;241m=\u001b[39m WingWeightMultiFidelitySmall()\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# define training and test set\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/botorch/test_functions/synthetic.py:84\u001b[0m, in \u001b[0;36mSyntheticTestFunction.__init__\u001b[0;34m(self, noise_std, negate, bounds, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds \u001b[38;5;241m=\u001b[39m bounds\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(noise_std\u001b[38;5;241m=\u001b[39mnoise_std, negate\u001b[38;5;241m=\u001b[39mnegate, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;66;03m# Ensure at least one optimizer lies within the custom bounds\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/botorch/test_functions/base.py:49\u001b[0m, in \u001b[0;36mBaseTestProblem.__init__\u001b[0;34m(self, noise_std, negate, dtype)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegate \u001b[38;5;241m=\u001b[39m negate\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InputDataError(\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the bounds to match the dimensionality of the domain. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds)\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_buffer(\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbounds\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds, dtype\u001b[38;5;241m=\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     56\u001b[0m )\n",
      "\u001b[0;31mInputDataError\u001b[0m: Expected the bounds to match the dimensionality of the domain. Got self.dim=6 and len(self._bounds)=7."
     ]
    }
   ],
   "source": [
    "problem = WingWeightMultiFidelitySmall()\n",
    "torch.manual_seed(0)\n",
    "# define training and test set\n",
    "N_TEST = 100\n",
    "fidelity_to_n = {0: 5, 1: 5, 2: 10, 3: 50}\n",
    "total_n = sum(fidelity_to_n.values())\n",
    "train_X = torch.rand(total_n, problem.dim, **tkwargs)\n",
    "train_X = unnormalize(train_X, bounds=problem.bounds)\n",
    "# set fidelities\n",
    "start = 0\n",
    "for fidelity, n in fidelity_to_n.items():\n",
    "    end = start + n\n",
    "    train_X[start:end, -1] = fidelity\n",
    "    start = end\n",
    "\n",
    "train_Y = problem(train_X).unsqueeze(-1)\n",
    "\n",
    "test_X = torch.rand(N_TEST, problem.dim, **tkwargs)\n",
    "test_X = unnormalize(test_X, bounds=problem.bounds)\n",
    "test_X[:, -1] = 0  # target fidelity\n",
    "test_Y = problem(test_X).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743529122103,
    "executionStopTime": 1743529259563,
    "language": "python",
    "originalKey": "16660295-7704-4fc8-86a6-865e818007df",
    "output": {
     "id": "644333568388982"
    },
    "outputsInitialized": true,
    "requestMsgId": "e061f189-346b-4b58-9716-bcee85df522f",
    "serverExecutionDuration": 136496.86142337,
    "showInput": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl9959/.local/lib/python3.12/site-packages/linear_operator/utils/interpolation.py:71: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
      "  summing_matrix = cls(summing_matrix_indices, summing_matrix_values, size)\n",
      "Sample: 100%|| 768/768 [07:22,  1.73it/s, step size=1.59e-01, acc. prob=0.842]\n",
      "/home/yl9959/.local/lib/python3.12/site-packages/botorch/models/utils/assorted.py:264: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n"
     ]
    }
   ],
   "source": [
    "wing_weight_res = eval_models_on_problem(problem, train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743529130077,
    "executionStopTime": 1743529260021,
    "language": "python",
    "originalKey": "76750e01-4e21-4bba-9624-fb214f9072aa",
    "output": {
     "id": "679472244421591"
    },
    "outputsInitialized": true,
    "requestMsgId": "1e7896ca-a923-47da-a3c8-32c28f5d34e9",
    "serverExecutionDuration": 3.9172596298158,
    "showInput": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wing_weight_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wing_weight_res\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wing_weight_res' is not defined"
     ]
    }
   ],
   "source": [
    "wing_weight_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "customInput": null,
    "language": "markdown",
    "originalKey": "3a4f34ce-9fdf-45cc-af1b-0be72caa11a2",
    "showInput": false
   },
   "source": [
    "## Borehole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528945358,
    "executionStopTime": 1743528946169,
    "language": "python",
    "originalKey": "02708c2d-b43a-4a8f-8aca-a99fb32c615d",
    "outputsInitialized": true,
    "requestMsgId": "c216c09b-5424-4008-88bd-56f191aad912",
    "serverExecutionDuration": 5.6033371947706,
    "showInput": true
   },
   "outputs": [],
   "source": [
    "problem = BoreholeMultiFidelity()\n",
    "torch.manual_seed(0)\n",
    "# define training and test set\n",
    "N_TEST = 100\n",
    "fidelity_to_n = {0: 5, 1: 5, 2: 25, 3: 5, 4: 25}\n",
    "total_n = sum(fidelity_to_n.values())\n",
    "train_X = torch.rand(total_n, problem.dim, **tkwargs)\n",
    "train_X = unnormalize(train_X, bounds=problem.bounds)\n",
    "# set fidelities\n",
    "start = 0\n",
    "for fidelity, n in fidelity_to_n.items():\n",
    "    end = start + n\n",
    "    train_X[start:end, -1] = fidelity\n",
    "    start = end\n",
    "\n",
    "train_Y = problem(train_X).unsqueeze(-1)\n",
    "\n",
    "test_X = torch.rand(N_TEST, problem.dim, **tkwargs)\n",
    "test_X = unnormalize(test_X, bounds=problem.bounds)\n",
    "test_X[:, -1] = 0  # target fidelity\n",
    "test_Y = problem(test_X).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743528947285,
    "executionStopTime": 1743529094868,
    "language": "python",
    "originalKey": "0d43b937-8f09-4d49-90d5-f4077ee2e646",
    "output": {
     "id": "2112932599153367"
    },
    "outputsInitialized": true,
    "requestMsgId": "fba253a7-c60a-412a-89be-3b4468f04999",
    "serverExecutionDuration": 146576.36261638,
    "showInput": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rWarmup:   0%|          | 0/768 [00:00, ?it/s]\n",
      "\rWarmup:   0%|          | 1/768 [00:01,  1.22s/it, step size=7.33e-01, acc. prob=0.125]\n",
      "\rWarmup:   0%|          | 3/768 [00:01,  2.82it/s, step size=7.87e-02, acc. prob=0.367]\n",
      "\rWarmup:   1%|          | 5/768 [00:01,  4.07it/s, step size=1.26e-01, acc. prob=0.599]\n",
      "\rWarmup:   1%|          | 7/768 [00:01,  5.47it/s, step size=2.73e-02, acc. prob=0.593]\n",
      "\rWarmup:   1%|          | 8/768 [00:01,  5.42it/s, step size=4.89e-02, acc. prob=0.644]\n",
      "\rWarmup:   1%|          | 9/768 [00:02,  5.37it/s, step size=8.65e-02, acc. prob=0.682]\n",
      "\rWarmup:   1%|         | 10/768 [00:02,  5.33it/s, step size=4.47e-02, acc. prob=0.673]\n",
      "\rWarmup:   1%|         | 11/768 [00:02,  5.31it/s, step size=8.07e-02, acc. prob=0.701]\n",
      "\rWarmup:   2%|         | 13/768 [00:02,  6.78it/s, step size=4.64e-02, acc. prob=0.702]\n",
      "\rWarmup:   2%|         | 14/768 [00:02,  6.34it/s, step size=8.68e-02, acc. prob=0.723]\n",
      "\rWarmup:   2%|         | 16/768 [00:03,  7.60it/s, step size=2.46e-02, acc. prob=0.706]\n",
      "\rWarmup:   2%|         | 17/768 [00:03,  6.92it/s, step size=4.68e-02, acc. prob=0.723]\n",
      "\rWarmup:   2%|         | 18/768 [00:03,  6.44it/s, step size=8.46e-02, acc. prob=0.738]\n",
      "\rWarmup:   3%|         | 20/768 [00:03,  6.69it/s, step size=2.26e-02, acc. prob=0.721]\n",
      "\rWarmup:   3%|         | 21/768 [00:03,  6.31it/s, step size=4.24e-02, acc. prob=0.734]\n",
      "\rWarmup:   3%|         | 22/768 [00:04,  6.04it/s, step size=7.84e-02, acc. prob=0.746]\n",
      "\rWarmup:   3%|         | 23/768 [00:04,  5.84it/s, step size=8.43e-02, acc. prob=0.749]\n",
      "\rWarmup:   3%|         | 24/768 [00:04,  5.69it/s, step size=1.46e-01, acc. prob=0.759]\n",
      "\rWarmup:   3%|         | 25/768 [00:04,  5.58it/s, step size=3.59e-02, acc. prob=0.741]\n",
      "\rWarmup:   3%|         | 26/768 [00:04,  5.50it/s, step size=6.53e-02, acc. prob=0.751]\n",
      "\rWarmup:   4%|         | 27/768 [00:05,  5.44it/s, step size=7.84e-02, acc. prob=0.754]\n",
      "\rWarmup:   4%|         | 29/768 [00:05,  7.00it/s, step size=1.54e-01, acc. prob=0.765]\n",
      "\rWarmup:   4%|         | 31/768 [00:05,  9.15it/s, step size=3.39e-02, acc. prob=0.749]\n",
      "\rWarmup:   4%|         | 33/768 [00:05,  7.24it/s, step size=1.02e-01, acc. prob=0.764]\n",
      "\rWarmup:   5%|         | 35/768 [00:05,  8.11it/s, step size=2.12e-01, acc. prob=0.773]\n",
      "\rWarmup:   5%|         | 37/768 [00:06,  8.34it/s, step size=4.71e-02, acc. prob=0.759]\n",
      "\rWarmup:   5%|         | 38/768 [00:06,  7.51it/s, step size=4.66e-02, acc. prob=0.759]\n",
      "\rWarmup:   5%|         | 39/768 [00:06,  6.89it/s, step size=7.88e-02, acc. prob=0.765]\n",
      "\rWarmup:   5%|         | 40/768 [00:06,  6.43it/s, step size=4.84e-02, acc. prob=0.761]\n",
      "\rWarmup:   5%|         | 41/768 [00:06,  6.08it/s, step size=4.16e-02, acc. prob=0.760]\n",
      "\rWarmup:   5%|         | 42/768 [00:07,  5.84it/s, step size=6.78e-02, acc. prob=0.766]\n",
      "\rWarmup:   6%|         | 43/768 [00:07,  5.67it/s, step size=1.08e-01, acc. prob=0.771]\n",
      "\rWarmup:   6%|         | 45/768 [00:07,  7.13it/s, step size=1.39e-01, acc. prob=0.774]\n",
      "\rWarmup:   6%|         | 47/768 [00:07,  8.15it/s, step size=4.01e-02, acc. prob=0.763]\n",
      "\rWarmup:   6%|         | 48/768 [00:07,  7.28it/s, step size=6.57e-02, acc. prob=0.768]\n",
      "\rWarmup:   6%|         | 49/768 [00:08,  6.68it/s, step size=9.64e-02, acc. prob=0.772]\n",
      "\rWarmup:   7%|         | 51/768 [00:08,  6.84it/s, step size=9.43e-02, acc. prob=0.773]\n",
      "\rWarmup:   7%|         | 53/768 [00:08,  6.91it/s, step size=7.90e-02, acc. prob=0.772]\n",
      "\rWarmup:   7%|         | 54/768 [00:08,  6.50it/s, step size=8.69e-02, acc. prob=0.773]\n",
      "\rWarmup:   7%|         | 56/768 [00:09,  7.60it/s, step size=1.17e-01, acc. prob=0.776]\n",
      "\rWarmup:   8%|         | 58/768 [00:09,  9.06it/s, step size=3.07e-02, acc. prob=0.766]\n",
      "\rWarmup:   8%|         | 59/768 [00:09,  7.92it/s, step size=4.87e-02, acc. prob=0.770]\n",
      "\rWarmup:   8%|         | 60/768 [00:09,  7.11it/s, step size=7.26e-02, acc. prob=0.773]\n",
      "\rWarmup:   8%|         | 61/768 [00:09,  6.52it/s, step size=8.40e-02, acc. prob=0.775]\n",
      "\rWarmup:   8%|         | 63/768 [00:10,  6.74it/s, step size=5.08e-02, acc. prob=0.772]\n",
      "\rWarmup:   8%|         | 64/768 [00:10,  6.35it/s, step size=6.41e-02, acc. prob=0.774]\n",
      "\rWarmup:   8%|         | 65/768 [00:10,  6.05it/s, step size=9.75e-02, acc. prob=0.777]\n",
      "\rWarmup:   9%|         | 66/768 [00:10,  5.82it/s, step size=1.41e-01, acc. prob=0.780]\n",
      "\rWarmup:   9%|         | 68/768 [00:10,  6.73it/s, step size=9.06e-02, acc. prob=0.777]\n",
      "\rWarmup:   9%|         | 69/768 [00:11,  6.32it/s, step size=7.58e-02, acc. prob=0.776]\n",
      "\rWarmup:   9%|         | 70/768 [00:11,  6.02it/s, step size=1.05e-01, acc. prob=0.778]\n",
      "\rWarmup:   9%|         | 72/768 [00:11,  7.34it/s, step size=1.05e-01, acc. prob=0.779]\n",
      "\rWarmup:  10%|         | 74/768 [00:11,  8.94it/s, step size=9.21e-02, acc. prob=0.778]\n",
      "\rWarmup:  10%|         | 76/768 [00:11, 10.24it/s, step size=1.87e-01, acc. prob=0.783]\n",
      "\rWarmup:  10%|         | 78/768 [00:11,  9.54it/s, step size=8.15e-02, acc. prob=0.778]\n",
      "\rWarmup:  10%|         | 80/768 [00:12,  7.58it/s, step size=6.92e-02, acc. prob=0.777]\n",
      "\rWarmup:  11%|         | 81/768 [00:12,  7.01it/s, step size=1.03e-01, acc. prob=0.780]\n",
      "\rWarmup:  11%|         | 83/768 [00:12,  6.98it/s, step size=7.53e-02, acc. prob=0.778]\n",
      "\rWarmup:  11%|         | 84/768 [00:12,  6.56it/s, step size=9.80e-02, acc. prob=0.780]\n",
      "\rWarmup:  11%|         | 86/768 [00:13,  7.62it/s, step size=1.11e-01, acc. prob=0.781]\n",
      "\rWarmup:  11%|        | 88/768 [00:13,  8.43it/s, step size=5.18e-02, acc. prob=0.777]\n",
      "\rWarmup:  12%|        | 89/768 [00:13,  7.52it/s, step size=2.65e-02, acc. prob=0.773]\n",
      "\rWarmup:  12%|        | 90/768 [00:13,  6.83it/s, step size=3.92e-02, acc. prob=0.776]\n",
      "\rWarmup:  12%|        | 91/768 [00:13,  6.35it/s, step size=5.79e-02, acc. prob=0.778]\n",
      "\rWarmup:  12%|        | 92/768 [00:14,  6.04it/s, step size=7.73e-02, acc. prob=0.780]\n",
      "\rWarmup:  12%|        | 94/768 [00:14,  7.39it/s, step size=1.03e-01, acc. prob=0.782]\n",
      "\rWarmup:  12%|        | 96/768 [00:14,  7.26it/s, step size=5.55e-02, acc. prob=0.779]\n",
      "\rWarmup:  13%|        | 97/768 [00:14,  6.71it/s, step size=8.00e-02, acc. prob=0.781]\n",
      "\rWarmup:  13%|        | 99/768 [00:15,  4.81it/s, step size=2.65e-01, acc. prob=0.784]\n",
      "\rWarmup:  13%|        | 100/768 [00:15,  4.89it/s, step size=8.29e-01, acc. prob=0.778]\n",
      "\rWarmup:  13%|        | 102/768 [00:15,  5.67it/s, step size=9.39e-02, acc. prob=0.772]\n",
      "\rWarmup:  13%|        | 103/768 [00:16,  5.56it/s, step size=1.26e-01, acc. prob=0.774]\n",
      "\rWarmup:  14%|        | 104/768 [00:16,  5.49it/s, step size=1.95e-01, acc. prob=0.776]\n",
      "\rWarmup:  14%|        | 105/768 [00:16,  5.43it/s, step size=1.40e-01, acc. prob=0.776]\n",
      "\rWarmup:  14%|        | 106/768 [00:16,  5.39it/s, step size=2.06e-01, acc. prob=0.777]\n",
      "\rWarmup:  14%|        | 107/768 [00:16,  5.36it/s, step size=6.74e-02, acc. prob=0.774]\n",
      "\rWarmup:  14%|        | 108/768 [00:16,  5.34it/s, step size=1.24e-01, acc. prob=0.776]\n",
      "\rWarmup:  14%|        | 109/768 [00:17,  5.32it/s, step size=1.62e-01, acc. prob=0.777]\n",
      "\rWarmup:  14%|        | 110/768 [00:17,  5.31it/s, step size=2.67e-01, acc. prob=0.779]\n",
      "\rWarmup:  14%|        | 111/768 [00:17,  5.30it/s, step size=4.13e-02, acc. prob=0.774]\n",
      "\rWarmup:  15%|        | 112/768 [00:17,  5.28it/s, step size=7.81e-02, acc. prob=0.776]\n",
      "\rWarmup:  15%|        | 113/768 [00:17,  5.26it/s, step size=1.47e-01, acc. prob=0.778]\n",
      "\rWarmup:  15%|        | 114/768 [00:18,  5.24it/s, step size=2.50e-01, acc. prob=0.779]\n",
      "\rWarmup:  15%|        | 115/768 [00:18,  5.23it/s, step size=1.97e-01, acc. prob=0.779]\n",
      "\rWarmup:  15%|        | 116/768 [00:18,  5.25it/s, step size=2.17e-01, acc. prob=0.779]\n",
      "\rWarmup:  15%|        | 117/768 [00:18,  5.26it/s, step size=5.51e-02, acc. prob=0.775]\n",
      "\rWarmup:  15%|        | 118/768 [00:18,  5.28it/s, step size=1.03e-01, acc. prob=0.777]\n",
      "\rWarmup:  15%|        | 119/768 [00:19,  5.29it/s, step size=1.88e-01, acc. prob=0.779]\n",
      "\rWarmup:  16%|        | 120/768 [00:19,  5.28it/s, step size=2.03e-01, acc. prob=0.779]\n",
      "\rWarmup:  16%|        | 121/768 [00:19,  5.26it/s, step size=6.64e-02, acc. prob=0.776]\n",
      "\rWarmup:  16%|        | 122/768 [00:19,  5.26it/s, step size=1.22e-01, acc. prob=0.778]\n",
      "\rWarmup:  16%|        | 123/768 [00:19,  5.28it/s, step size=2.12e-01, acc. prob=0.780]\n",
      "\rWarmup:  16%|        | 124/768 [00:20,  5.29it/s, step size=4.78e-02, acc. prob=0.776]\n",
      "\rWarmup:  16%|        | 125/768 [00:20,  5.29it/s, step size=8.68e-02, acc. prob=0.777]\n",
      "\rWarmup:  16%|        | 126/768 [00:20,  5.30it/s, step size=1.51e-01, acc. prob=0.779]\n",
      "\rWarmup:  17%|        | 127/768 [00:20,  5.31it/s, step size=2.36e-01, acc. prob=0.780]\n",
      "\rWarmup:  17%|        | 128/768 [00:20,  5.30it/s, step size=2.15e-01, acc. prob=0.780]\n",
      "\rWarmup:  17%|        | 129/768 [00:20,  5.28it/s, step size=4.67e-02, acc. prob=0.776]\n",
      "\rWarmup:  17%|        | 130/768 [00:21,  5.30it/s, step size=8.30e-02, acc. prob=0.778]\n",
      "\rWarmup:  17%|        | 131/768 [00:21,  5.31it/s, step size=1.43e-01, acc. prob=0.779]\n",
      "\rWarmup:  17%|        | 132/768 [00:21,  5.29it/s, step size=1.49e-01, acc. prob=0.780]\n",
      "\rWarmup:  17%|        | 133/768 [00:21,  5.26it/s, step size=3.68e-02, acc. prob=0.776]\n",
      "\rWarmup:  17%|        | 134/768 [00:21,  5.25it/s, step size=6.44e-02, acc. prob=0.777]\n",
      "\rWarmup:  18%|        | 135/768 [00:22,  5.24it/s, step size=1.07e-01, acc. prob=0.779]\n",
      "\rWarmup:  18%|        | 136/768 [00:22,  5.23it/s, step size=1.72e-01, acc. prob=0.780]\n",
      "\rWarmup:  18%|        | 137/768 [00:22,  5.22it/s, step size=2.72e-01, acc. prob=0.782]\n",
      "\rWarmup:  18%|        | 138/768 [00:22,  5.21it/s, step size=1.04e-01, acc. prob=0.779]\n",
      "\rWarmup:  18%|        | 139/768 [00:22,  5.22it/s, step size=5.60e-02, acc. prob=0.777]\n",
      "\rWarmup:  18%|        | 140/768 [00:23,  5.23it/s, step size=9.28e-02, acc. prob=0.779]\n",
      "\rWarmup:  18%|        | 141/768 [00:23,  5.23it/s, step size=1.56e-01, acc. prob=0.781]\n",
      "\rWarmup:  18%|        | 142/768 [00:23,  5.23it/s, step size=7.33e-02, acc. prob=0.778]\n",
      "\rWarmup:  19%|        | 143/768 [00:23,  5.22it/s, step size=1.08e-01, acc. prob=0.780]\n",
      "\rWarmup:  19%|        | 144/768 [00:23,  5.22it/s, step size=1.68e-01, acc. prob=0.781]\n",
      "\rWarmup:  19%|        | 145/768 [00:24,  5.23it/s, step size=2.23e-01, acc. prob=0.782]\n",
      "\rWarmup:  19%|        | 146/768 [00:24,  5.24it/s, step size=6.15e-02, acc. prob=0.778]\n",
      "\rWarmup:  19%|        | 147/768 [00:24,  5.26it/s, step size=9.91e-02, acc. prob=0.780]\n",
      "\rWarmup:  19%|        | 148/768 [00:24,  5.26it/s, step size=1.62e-01, acc. prob=0.781]\n",
      "\rWarmup:  19%|        | 149/768 [00:24,  5.04it/s, step size=7.25e-01, acc. prob=0.778]\n",
      "\rWarmup:  20%|        | 152/768 [00:25,  7.36it/s, step size=5.27e-02, acc. prob=0.766]\n",
      "\rWarmup:  20%|        | 153/768 [00:25,  6.77it/s, step size=6.48e-02, acc. prob=0.767]\n",
      "\rWarmup:  20%|        | 154/768 [00:25,  6.33it/s, step size=9.58e-02, acc. prob=0.769]\n",
      "\rWarmup:  20%|        | 155/768 [00:25,  6.01it/s, step size=1.56e-01, acc. prob=0.770]\n",
      "\rWarmup:  20%|        | 156/768 [00:25,  5.80it/s, step size=2.73e-01, acc. prob=0.772]\n",
      "\rWarmup:  20%|        | 157/768 [00:26,  5.65it/s, step size=3.79e-01, acc. prob=0.773]\n",
      "\rWarmup:  21%|        | 158/768 [00:26,  5.54it/s, step size=1.14e-01, acc. prob=0.771]\n",
      "\rWarmup:  21%|        | 159/768 [00:26,  5.47it/s, step size=2.06e-01, acc. prob=0.772]\n",
      "\rWarmup:  21%|        | 160/768 [00:26,  5.42it/s, step size=1.00e-01, acc. prob=0.771]\n",
      "\rWarmup:  21%|        | 161/768 [00:26,  5.38it/s, step size=1.90e-01, acc. prob=0.772]\n",
      "\rWarmup:  21%|        | 162/768 [00:26,  5.36it/s, step size=3.57e-01, acc. prob=0.773]\n",
      "\rWarmup:  21%|        | 163/768 [00:27,  5.34it/s, step size=3.60e-01, acc. prob=0.774]\n",
      "\rWarmup:  21%|       | 164/768 [00:27,  5.30it/s, step size=6.80e-01, acc. prob=0.775]\n",
      "\rWarmup:  21%|       | 165/768 [00:27,  5.26it/s, step size=1.09e-01, acc. prob=0.772]\n",
      "\rWarmup:  22%|       | 166/768 [00:27,  5.25it/s, step size=2.06e-01, acc. prob=0.773]\n",
      "\rWarmup:  22%|       | 167/768 [00:27,  5.25it/s, step size=3.79e-01, acc. prob=0.774]\n",
      "\rWarmup:  22%|       | 168/768 [00:28,  5.27it/s, step size=1.98e-01, acc. prob=0.773]\n",
      "\rWarmup:  22%|       | 169/768 [00:28,  5.27it/s, step size=3.06e-01, acc. prob=0.774]\n",
      "\rWarmup:  22%|       | 170/768 [00:28,  5.28it/s, step size=5.51e-01, acc. prob=0.775]\n",
      "\rWarmup:  22%|       | 171/768 [00:28,  5.28it/s, step size=7.67e-02, acc. prob=0.771]\n",
      "\rWarmup:  22%|       | 172/768 [00:28,  5.28it/s, step size=1.42e-01, acc. prob=0.773]\n",
      "\rWarmup:  23%|       | 173/768 [00:29,  5.29it/s, step size=1.42e-01, acc. prob=0.773]\n",
      "\rWarmup:  23%|       | 174/768 [00:29,  5.29it/s, step size=2.59e-01, acc. prob=0.774]\n",
      "\rWarmup:  23%|       | 175/768 [00:29,  5.30it/s, step size=1.41e-01, acc. prob=0.773]\n",
      "\rWarmup:  23%|       | 176/768 [00:29,  5.28it/s, step size=2.52e-01, acc. prob=0.774]\n",
      "\rWarmup:  23%|       | 177/768 [00:29,  5.22it/s, step size=1.91e-01, acc. prob=0.774]\n",
      "\rWarmup:  23%|       | 178/768 [00:30,  5.25it/s, step size=3.11e-01, acc. prob=0.775]\n",
      "\rWarmup:  23%|       | 179/768 [00:30,  5.26it/s, step size=2.12e-01, acc. prob=0.774]\n",
      "\rWarmup:  23%|       | 180/768 [00:30,  5.27it/s, step size=2.46e-01, acc. prob=0.775]\n",
      "\rWarmup:  24%|       | 181/768 [00:30,  5.27it/s, step size=1.13e-01, acc. prob=0.773]\n",
      "\rWarmup:  24%|       | 182/768 [00:30,  5.27it/s, step size=1.99e-01, acc. prob=0.774]\n",
      "\rWarmup:  24%|       | 183/768 [00:30,  5.28it/s, step size=3.45e-01, acc. prob=0.775]\n",
      "\rWarmup:  24%|       | 184/768 [00:31,  5.28it/s, step size=5.73e-01, acc. prob=0.777]\n",
      "\rWarmup:  24%|       | 185/768 [00:31,  5.27it/s, step size=1.50e-01, acc. prob=0.774]\n",
      "\rWarmup:  24%|       | 186/768 [00:31,  5.26it/s, step size=2.57e-01, acc. prob=0.775]\n",
      "\rWarmup:  24%|       | 187/768 [00:31,  5.25it/s, step size=3.37e-01, acc. prob=0.776]\n",
      "\rWarmup:  24%|       | 188/768 [00:31,  5.26it/s, step size=3.87e-01, acc. prob=0.776]\n",
      "\rWarmup:  25%|       | 189/768 [00:32,  5.25it/s, step size=3.86e-01, acc. prob=0.776]\n",
      "\rWarmup:  25%|       | 190/768 [00:32,  5.25it/s, step size=1.51e-01, acc. prob=0.774]\n",
      "\rWarmup:  25%|       | 191/768 [00:32,  5.26it/s, step size=2.45e-01, acc. prob=0.775]\n",
      "\rWarmup:  25%|       | 192/768 [00:32,  5.25it/s, step size=4.10e-01, acc. prob=0.777]\n",
      "\rWarmup:  25%|       | 193/768 [00:32,  5.26it/s, step size=9.62e-02, acc. prob=0.774]\n",
      "\rWarmup:  25%|       | 194/768 [00:33,  5.26it/s, step size=1.62e-01, acc. prob=0.775]\n",
      "\rWarmup:  25%|       | 195/768 [00:33,  5.26it/s, step size=2.45e-01, acc. prob=0.776]\n",
      "\rWarmup:  26%|       | 196/768 [00:33,  5.27it/s, step size=1.59e-01, acc. prob=0.775]\n",
      "\rWarmup:  26%|       | 197/768 [00:33,  5.27it/s, step size=2.51e-01, acc. prob=0.776]\n",
      "\rWarmup:  26%|       | 198/768 [00:33,  5.27it/s, step size=2.70e-01, acc. prob=0.776]\n",
      "\rWarmup:  26%|       | 199/768 [00:34,  5.28it/s, step size=1.23e-01, acc. prob=0.775]\n",
      "\rWarmup:  26%|       | 200/768 [00:34,  5.28it/s, step size=2.00e-01, acc. prob=0.776]\n",
      "\rWarmup:  26%|       | 201/768 [00:34,  5.28it/s, step size=3.04e-01, acc. prob=0.777]\n",
      "\rWarmup:  26%|       | 202/768 [00:34,  5.28it/s, step size=1.41e-01, acc. prob=0.775]\n",
      "\rWarmup:  26%|       | 203/768 [00:34,  5.27it/s, step size=2.25e-01, acc. prob=0.776]\n",
      "\rWarmup:  27%|       | 204/768 [00:34,  5.27it/s, step size=3.46e-01, acc. prob=0.777]\n",
      "\rWarmup:  27%|       | 205/768 [00:35,  5.27it/s, step size=4.07e-01, acc. prob=0.778]\n",
      "\rWarmup:  27%|       | 206/768 [00:35,  5.27it/s, step size=1.61e-01, acc. prob=0.776]\n",
      "\rWarmup:  27%|       | 207/768 [00:35,  5.27it/s, step size=2.52e-01, acc. prob=0.777]\n",
      "\rWarmup:  27%|       | 208/768 [00:35,  5.26it/s, step size=2.01e-01, acc. prob=0.776]\n",
      "\rWarmup:  27%|       | 209/768 [00:35,  5.27it/s, step size=2.58e-01, acc. prob=0.777]\n",
      "\rWarmup:  27%|       | 210/768 [00:36,  5.28it/s, step size=3.58e-01, acc. prob=0.778]\n",
      "\rWarmup:  27%|       | 211/768 [00:36,  5.29it/s, step size=1.99e-01, acc. prob=0.776]\n",
      "\rWarmup:  28%|       | 212/768 [00:36,  5.29it/s, step size=2.37e-01, acc. prob=0.777]\n",
      "\rWarmup:  28%|       | 213/768 [00:36,  5.29it/s, step size=3.68e-01, acc. prob=0.778]\n",
      "\rWarmup:  28%|       | 214/768 [00:36,  5.29it/s, step size=5.21e-01, acc. prob=0.779]\n",
      "\rWarmup:  28%|       | 215/768 [00:37,  5.29it/s, step size=2.29e-01, acc. prob=0.777]\n",
      "\rWarmup:  28%|       | 216/768 [00:37,  5.28it/s, step size=3.32e-01, acc. prob=0.778]\n",
      "\rWarmup:  28%|       | 217/768 [00:37,  5.28it/s, step size=4.86e-01, acc. prob=0.779]\n",
      "\rWarmup:  28%|       | 218/768 [00:37,  5.26it/s, step size=5.62e-01, acc. prob=0.779]\n",
      "\rWarmup:  29%|       | 219/768 [00:37,  5.22it/s, step size=2.64e-01, acc. prob=0.778]\n",
      "\rWarmup:  29%|       | 220/768 [00:37,  5.23it/s, step size=3.69e-01, acc. prob=0.778]\n",
      "\rWarmup:  29%|       | 221/768 [00:38,  5.24it/s, step size=1.62e-01, acc. prob=0.777]\n",
      "\rWarmup:  29%|       | 222/768 [00:38,  5.26it/s, step size=2.32e-01, acc. prob=0.777]\n",
      "\rWarmup:  29%|       | 223/768 [00:38,  5.26it/s, step size=3.55e-01, acc. prob=0.778]\n",
      "\rWarmup:  29%|       | 224/768 [00:38,  5.26it/s, step size=4.69e-01, acc. prob=0.779]\n",
      "\rWarmup:  29%|       | 225/768 [00:38,  5.27it/s, step size=2.17e-01, acc. prob=0.777]\n",
      "\rWarmup:  29%|       | 226/768 [00:39,  5.28it/s, step size=2.69e-01, acc. prob=0.778]\n",
      "\rWarmup:  30%|       | 227/768 [00:39,  5.29it/s, step size=2.65e-01, acc. prob=0.778]\n",
      "\rWarmup:  30%|       | 228/768 [00:39,  5.29it/s, step size=2.82e-01, acc. prob=0.778]\n",
      "\rWarmup:  30%|       | 229/768 [00:39,  5.28it/s, step size=1.47e-01, acc. prob=0.777]\n",
      "\rWarmup:  30%|       | 230/768 [00:39,  5.28it/s, step size=1.48e-01, acc. prob=0.777]\n",
      "\rWarmup:  30%|       | 231/768 [00:40,  5.28it/s, step size=2.23e-01, acc. prob=0.778]\n",
      "\rWarmup:  30%|       | 232/768 [00:40,  5.29it/s, step size=2.84e-01, acc. prob=0.778]\n",
      "\rWarmup:  30%|       | 233/768 [00:40,  5.24it/s, step size=1.03e-01, acc. prob=0.776]\n",
      "\rWarmup:  30%|       | 234/768 [00:40,  5.26it/s, step size=1.52e-01, acc. prob=0.777]\n",
      "\rWarmup:  31%|       | 235/768 [00:40,  5.26it/s, step size=1.92e-01, acc. prob=0.778]\n",
      "\rWarmup:  31%|       | 236/768 [00:41,  5.27it/s, step size=2.60e-01, acc. prob=0.779]\n",
      "\rWarmup:  31%|       | 237/768 [00:41,  5.28it/s, step size=3.12e-01, acc. prob=0.779]\n",
      "\rWarmup:  31%|       | 238/768 [00:41,  5.29it/s, step size=3.40e-01, acc. prob=0.779]\n",
      "\rWarmup:  31%|       | 239/768 [00:41,  5.28it/s, step size=3.16e-01, acc. prob=0.779]\n",
      "\rWarmup:  31%|      | 240/768 [00:41,  5.27it/s, step size=4.06e-01, acc. prob=0.780]\n",
      "\rWarmup:  31%|      | 241/768 [00:41,  5.28it/s, step size=4.46e-01, acc. prob=0.780]\n",
      "\rWarmup:  32%|      | 242/768 [00:42,  5.28it/s, step size=4.45e-01, acc. prob=0.780]\n",
      "\rWarmup:  32%|      | 243/768 [00:42,  5.28it/s, step size=4.68e-01, acc. prob=0.780]\n",
      "\rWarmup:  32%|      | 244/768 [00:42,  5.28it/s, step size=3.77e-01, acc. prob=0.780]\n",
      "\rWarmup:  32%|      | 245/768 [00:42,  5.27it/s, step size=2.38e-01, acc. prob=0.779]\n",
      "\rWarmup:  32%|      | 246/768 [00:42,  5.26it/s, step size=2.53e-01, acc. prob=0.779]\n",
      "\rWarmup:  32%|      | 247/768 [00:43,  5.25it/s, step size=2.04e-01, acc. prob=0.779]\n",
      "\rWarmup:  32%|      | 248/768 [00:43,  5.25it/s, step size=2.76e-01, acc. prob=0.779]\n",
      "\rWarmup:  32%|      | 249/768 [00:43,  5.13it/s, step size=7.70e-01, acc. prob=0.780]\n",
      "\rWarmup:  33%|      | 252/768 [00:43,  7.93it/s, step size=1.22e-01, acc. prob=0.774]\n",
      "\rWarmup:  33%|      | 253/768 [00:43,  7.12it/s, step size=1.32e-01, acc. prob=0.775]\n",
      "\rWarmup:  33%|      | 254/768 [00:44,  6.55it/s, step size=1.80e-01, acc. prob=0.776]\n",
      "\rWarmup:  33%|      | 256/768 [00:44,  6.74it/s, step size=2.60e-01, acc. prob=0.776]\n",
      "\rWarmup:  34%|      | 258/768 [00:44,  7.31it/s, step size=1.44e-01, acc. prob=0.776]\n",
      "\rWarmup:  34%|      | 259/768 [00:44,  6.78it/s, step size=2.63e-01, acc. prob=0.777]\n",
      "\rWarmup:  34%|      | 260/768 [00:45,  6.37it/s, step size=2.00e-01, acc. prob=0.777]\n",
      "\rWarmup:  34%|      | 261/768 [00:45,  6.01it/s, step size=1.45e-01, acc. prob=0.776]\n",
      "\rWarmup:  34%|      | 262/768 [00:45,  5.79it/s, step size=2.40e-01, acc. prob=0.777]\n",
      "\rWarmup:  34%|      | 264/768 [00:45,  7.74it/s, step size=3.18e-01, acc. prob=0.777]\n",
      "\rWarmup:  35%|      | 266/768 [00:45,  8.60it/s, step size=3.40e-02, acc. prob=0.775]\n",
      "\rWarmup:  35%|      | 267/768 [00:45,  7.57it/s, step size=6.49e-02, acc. prob=0.776]\n",
      "\rWarmup:  35%|      | 268/768 [00:46,  6.86it/s, step size=1.19e-01, acc. prob=0.776]\n",
      "\rWarmup:  35%|      | 269/768 [00:46,  6.36it/s, step size=2.19e-01, acc. prob=0.777]\n",
      "\rWarmup:  35%|      | 271/768 [00:46,  7.63it/s, step size=3.87e-01, acc. prob=0.778]\n",
      "\rWarmup:  35%|      | 272/768 [00:46,  7.47it/s, step size=5.14e-01, acc. prob=0.778]\n",
      "\rWarmup:  36%|      | 274/768 [00:46,  9.18it/s, step size=2.04e-01, acc. prob=0.777]\n",
      "\rWarmup:  36%|      | 275/768 [00:46,  7.85it/s, step size=3.64e-01, acc. prob=0.778]\n",
      "\rWarmup:  36%|      | 276/768 [00:47,  7.03it/s, step size=1.64e-01, acc. prob=0.777]\n",
      "\rWarmup:  36%|      | 277/768 [00:47,  6.48it/s, step size=2.74e-01, acc. prob=0.778]\n",
      "\rWarmup:  36%|      | 278/768 [00:47,  6.10it/s, step size=1.79e-01, acc. prob=0.777]\n",
      "\rWarmup:  36%|      | 279/768 [00:47,  5.83it/s, step size=1.17e-01, acc. prob=0.777]\n",
      "\rWarmup:  36%|      | 280/768 [00:47,  5.65it/s, step size=2.07e-01, acc. prob=0.778]\n",
      "\rWarmup:  37%|      | 282/768 [00:48,  6.22it/s, step size=8.80e-02, acc. prob=0.777]\n",
      "\rWarmup:  37%|      | 283/768 [00:48,  5.97it/s, step size=1.53e-01, acc. prob=0.777]\n",
      "\rWarmup:  37%|      | 285/768 [00:48,  6.38it/s, step size=5.91e-02, acc. prob=0.776]\n",
      "\rWarmup:  37%|      | 286/768 [00:48,  6.10it/s, step size=1.02e-01, acc. prob=0.777]\n",
      "\rWarmup:  37%|      | 287/768 [00:49,  5.85it/s, step size=1.77e-01, acc. prob=0.778]\n",
      "\rWarmup:  38%|      | 288/768 [00:49,  5.71it/s, step size=2.83e-01, acc. prob=0.778]\n",
      "\rWarmup:  38%|      | 289/768 [00:49,  5.59it/s, step size=4.48e-01, acc. prob=0.779]\n",
      "\rWarmup:  38%|      | 291/768 [00:49,  6.14it/s, step size=3.57e-01, acc. prob=0.779]\n",
      "\rWarmup:  38%|      | 293/768 [00:49,  6.46it/s, step size=1.48e-01, acc. prob=0.778]\n",
      "\rWarmup:  38%|      | 294/768 [00:50,  6.18it/s, step size=2.47e-01, acc. prob=0.778]\n",
      "\rWarmup:  38%|      | 295/768 [00:50,  5.95it/s, step size=4.09e-01, acc. prob=0.779]\n",
      "\rWarmup:  39%|      | 297/768 [00:50,  6.40it/s, step size=1.19e-01, acc. prob=0.777]\n",
      "\rWarmup:  39%|      | 298/768 [00:50,  6.12it/s, step size=1.97e-01, acc. prob=0.778]\n",
      "\rWarmup:  39%|      | 299/768 [00:51,  5.90it/s, step size=3.21e-01, acc. prob=0.779]\n",
      "\rWarmup:  39%|      | 301/768 [00:51,  7.24it/s, step size=1.55e-01, acc. prob=0.778]\n",
      "\rWarmup:  39%|      | 302/768 [00:51,  6.71it/s, step size=2.15e-01, acc. prob=0.778]\n",
      "\rWarmup:  40%|      | 304/768 [00:51,  7.87it/s, step size=2.83e-01, acc. prob=0.779]\n",
      "\rWarmup:  40%|      | 306/768 [00:51,  9.40it/s, step size=1.88e-01, acc. prob=0.778]\n",
      "\rWarmup:  40%|      | 308/768 [00:51,  9.82it/s, step size=2.71e-01, acc. prob=0.779]\n",
      "\rWarmup:  40%|      | 310/768 [00:52,  8.76it/s, step size=2.07e-01, acc. prob=0.779]\n",
      "\rWarmup:  40%|      | 311/768 [00:52,  7.81it/s, step size=2.03e-01, acc. prob=0.779]\n",
      "\rWarmup:  41%|      | 312/768 [00:52,  7.10it/s, step size=2.71e-01, acc. prob=0.779]\n",
      "\rWarmup:  41%|      | 314/768 [00:52,  8.14it/s, step size=5.25e-01, acc. prob=0.780]\n",
      "\rWarmup:  41%|      | 316/768 [00:53,  7.77it/s, step size=2.32e-01, acc. prob=0.779]\n",
      "\rWarmup:  41%|     | 317/768 [00:53,  7.10it/s, step size=3.18e-01, acc. prob=0.780]\n",
      "\rWarmup:  42%|     | 319/768 [00:53,  7.09it/s, step size=1.71e-01, acc. prob=0.779]\n",
      "\rWarmup:  42%|     | 320/768 [00:53,  6.63it/s, step size=2.56e-01, acc. prob=0.779]\n",
      "\rWarmup:  42%|     | 321/768 [00:53,  6.28it/s, step size=1.53e-01, acc. prob=0.779]\n",
      "\rWarmup:  42%|     | 322/768 [00:54,  6.00it/s, step size=2.28e-01, acc. prob=0.779]\n",
      "\rWarmup:  42%|     | 324/768 [00:54,  7.33it/s, step size=3.47e-01, acc. prob=0.780]\n",
      "\rWarmup:  42%|     | 325/768 [00:54,  6.67it/s, step size=8.82e-02, acc. prob=0.778]\n",
      "\rWarmup:  42%|     | 326/768 [00:54,  6.20it/s, step size=1.34e-01, acc. prob=0.779]\n",
      "\rWarmup:  43%|     | 328/768 [00:54,  6.48it/s, step size=8.93e-02, acc. prob=0.778]\n",
      "\rWarmup:  43%|     | 329/768 [00:55,  6.18it/s, step size=1.31e-01, acc. prob=0.779]\n",
      "\rWarmup:  43%|     | 330/768 [00:55,  5.95it/s, step size=1.94e-01, acc. prob=0.779]\n",
      "\rWarmup:  43%|     | 331/768 [00:55,  5.76it/s, step size=2.86e-01, acc. prob=0.780]\n",
      "\rWarmup:  43%|     | 332/768 [00:55,  6.00it/s, step size=9.37e-02, acc. prob=0.778]\n",
      "\rWarmup:  43%|     | 333/768 [00:55,  5.72it/s, step size=1.30e-01, acc. prob=0.779]\n",
      "\rWarmup:  43%|     | 334/768 [00:56,  5.61it/s, step size=1.96e-01, acc. prob=0.780]\n",
      "\rWarmup:  44%|     | 335/768 [00:56,  5.52it/s, step size=2.90e-01, acc. prob=0.780]\n",
      "\rWarmup:  44%|     | 337/768 [00:56,  7.09it/s, step size=2.81e-01, acc. prob=0.780]\n",
      "\rWarmup:  44%|     | 338/768 [00:56,  6.56it/s, step size=4.17e-01, acc. prob=0.781]\n",
      "\rWarmup:  44%|     | 340/768 [00:56,  6.75it/s, step size=1.24e-01, acc. prob=0.779]\n",
      "\rWarmup:  44%|     | 341/768 [00:57,  6.31it/s, step size=1.82e-01, acc. prob=0.780]\n",
      "\rWarmup:  45%|     | 342/768 [00:57,  6.01it/s, step size=8.06e-02, acc. prob=0.778]\n",
      "\rWarmup:  45%|     | 343/768 [00:57,  5.80it/s, step size=1.17e-01, acc. prob=0.779]\n",
      "\rWarmup:  45%|     | 344/768 [00:57,  5.63it/s, step size=1.70e-01, acc. prob=0.780]\n",
      "\rWarmup:  45%|     | 345/768 [00:57,  5.52it/s, step size=2.49e-01, acc. prob=0.780]\n",
      "\rWarmup:  45%|     | 346/768 [00:58,  5.46it/s, step size=3.05e-01, acc. prob=0.781]\n",
      "\rWarmup:  45%|     | 348/768 [00:58,  6.11it/s, step size=1.32e-01, acc. prob=0.779]\n",
      "\rWarmup:  46%|     | 350/768 [00:58,  6.47it/s, step size=1.91e-01, acc. prob=0.780]\n",
      "\rWarmup:  46%|     | 351/768 [00:58,  6.18it/s, step size=2.19e-01, acc. prob=0.780]\n",
      "\rWarmup:  46%|     | 352/768 [00:58,  5.96it/s, step size=1.39e-01, acc. prob=0.780]\n",
      "\rWarmup:  46%|     | 353/768 [00:59,  5.79it/s, step size=2.01e-01, acc. prob=0.780]\n",
      "\rWarmup:  46%|     | 354/768 [00:59,  5.66it/s, step size=2.48e-01, acc. prob=0.781]\n",
      "\rWarmup:  46%|     | 355/768 [00:59,  5.58it/s, step size=3.46e-01, acc. prob=0.781]\n",
      "\rWarmup:  46%|     | 357/768 [00:59,  7.08it/s, step size=2.98e-01, acc. prob=0.781]\n",
      "\rWarmup:  47%|     | 359/768 [00:59,  7.12it/s, step size=3.60e-01, acc. prob=0.781]\n",
      "\rWarmup:  47%|     | 360/768 [01:00,  6.65it/s, step size=1.28e-01, acc. prob=0.780]\n",
      "\rWarmup:  47%|     | 361/768 [01:00,  6.28it/s, step size=1.82e-01, acc. prob=0.780]\n",
      "\rWarmup:  47%|     | 362/768 [01:00,  6.02it/s, step size=1.51e-01, acc. prob=0.780]\n",
      "\rWarmup:  47%|     | 363/768 [01:00,  5.82it/s, step size=1.17e-01, acc. prob=0.780]\n",
      "\rWarmup:  47%|     | 364/768 [01:00,  5.68it/s, step size=1.64e-01, acc. prob=0.780]\n",
      "\rWarmup:  48%|     | 365/768 [01:01,  5.59it/s, step size=5.38e-02, acc. prob=0.778]\n",
      "\rWarmup:  48%|     | 366/768 [01:01,  5.52it/s, step size=7.69e-02, acc. prob=0.779]\n",
      "\rWarmup:  48%|     | 367/768 [01:01,  5.45it/s, step size=1.09e-01, acc. prob=0.780]\n",
      "\rWarmup:  48%|     | 368/768 [01:01,  5.41it/s, step size=1.53e-01, acc. prob=0.780]\n",
      "\rWarmup:  48%|     | 369/768 [01:01,  5.36it/s, step size=1.74e-01, acc. prob=0.780]\n",
      "\rWarmup:  48%|     | 370/768 [01:02,  5.33it/s, step size=1.90e-01, acc. prob=0.781]\n",
      "\rWarmup:  48%|     | 371/768 [01:02,  5.34it/s, step size=2.07e-01, acc. prob=0.781]\n",
      "\rWarmup:  48%|     | 372/768 [01:02,  5.33it/s, step size=1.38e-01, acc. prob=0.780]\n",
      "\rWarmup:  49%|     | 373/768 [01:02,  5.33it/s, step size=1.92e-01, acc. prob=0.781]\n",
      "\rWarmup:  49%|     | 375/768 [01:02,  6.05it/s, step size=3.33e-01, acc. prob=0.782]\n",
      "\rWarmup:  49%|     | 376/768 [01:03,  5.86it/s, step size=2.25e-01, acc. prob=0.781]\n",
      "\rWarmup:  49%|     | 377/768 [01:03,  5.72it/s, step size=2.27e-01, acc. prob=0.781]\n",
      "\rWarmup:  49%|     | 378/768 [01:03,  5.62it/s, step size=2.21e-01, acc. prob=0.781]\n",
      "\rWarmup:  49%|     | 379/768 [01:03,  5.54it/s, step size=2.57e-01, acc. prob=0.781]\n",
      "\rWarmup:  49%|     | 380/768 [01:03,  5.48it/s, step size=3.10e-01, acc. prob=0.782]\n",
      "\rWarmup:  50%|     | 381/768 [01:03,  5.88it/s, step size=1.54e-01, acc. prob=0.781]\n",
      "\rWarmup:  50%|     | 382/768 [01:04,  5.71it/s, step size=2.15e-01, acc. prob=0.781]\n",
      "\rWarmup:  50%|     | 383/768 [01:04,  5.60it/s, step size=2.89e-01, acc. prob=0.782]\n",
      "\rWarmup:  50%|     | 385/768 [01:04,  6.21it/s, step size=1.88e-01, acc. prob=0.781]\n",
      "\rWarmup:  50%|     | 386/768 [01:04,  5.95it/s, step size=2.08e-01, acc. prob=0.781]\n",
      "\rWarmup:  50%|     | 387/768 [01:04,  5.77it/s, step size=2.75e-01, acc. prob=0.782]\n",
      "\rWarmup:  51%|     | 389/768 [01:05,  6.29it/s, step size=2.98e-01, acc. prob=0.782]\n",
      "\rWarmup:  51%|     | 391/768 [01:05,  8.00it/s, step size=2.90e-01, acc. prob=0.782]\n",
      "\rWarmup:  51%|     | 392/768 [01:05,  7.24it/s, step size=3.76e-01, acc. prob=0.782]\n",
      "\rWarmup:  51%|     | 393/768 [01:05,  6.68it/s, step size=1.75e-01, acc. prob=0.781]\n",
      "\rWarmup:  51%|    | 395/768 [01:06,  6.88it/s, step size=1.56e-01, acc. prob=0.781]\n",
      "\rWarmup:  52%|    | 396/768 [01:06,  6.48it/s, step size=2.15e-01, acc. prob=0.782]\n",
      "\rWarmup:  52%|    | 397/768 [01:06,  6.17it/s, step size=2.93e-01, acc. prob=0.782]\n",
      "\rWarmup:  52%|    | 399/768 [01:06,  6.55it/s, step size=1.35e-01, acc. prob=0.781]\n",
      "\rWarmup:  52%|    | 400/768 [01:06,  6.24it/s, step size=1.85e-01, acc. prob=0.782]\n",
      "\rWarmup:  52%|    | 401/768 [01:07,  5.99it/s, step size=2.37e-01, acc. prob=0.782]\n",
      "\rWarmup:  52%|    | 402/768 [01:07,  5.81it/s, step size=3.04e-01, acc. prob=0.782]\n",
      "\rWarmup:  53%|    | 404/768 [01:07,  6.74it/s, step size=2.56e-01, acc. prob=0.782]\n",
      "\rWarmup:  53%|    | 406/768 [01:07,  6.90it/s, step size=3.04e-01, acc. prob=0.783]\n",
      "\rWarmup:  53%|    | 407/768 [01:07,  6.49it/s, step size=1.49e-01, acc. prob=0.781]\n",
      "\rWarmup:  53%|    | 408/768 [01:08,  6.19it/s, step size=1.89e-01, acc. prob=0.782]\n",
      "\rWarmup:  53%|    | 409/768 [01:08,  5.94it/s, step size=2.44e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 411/768 [01:08,  6.32it/s, step size=1.73e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 412/768 [01:08,  6.00it/s, step size=2.31e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 413/768 [01:09,  5.77it/s, step size=1.09e-01, acc. prob=0.781]\n",
      "\rWarmup:  54%|    | 414/768 [01:09,  5.62it/s, step size=1.47e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 415/768 [01:09,  5.53it/s, step size=1.96e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 416/768 [01:09,  5.47it/s, step size=2.38e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 417/768 [01:09,  5.41it/s, step size=2.19e-01, acc. prob=0.782]\n",
      "\rWarmup:  54%|    | 418/768 [01:09,  5.38it/s, step size=2.87e-01, acc. prob=0.783]\n",
      "\rWarmup:  55%|    | 420/768 [01:10,  7.51it/s, step size=4.32e-01, acc. prob=0.783]\n",
      "\rWarmup:  55%|    | 422/768 [01:10,  8.87it/s, step size=2.35e-01, acc. prob=0.783]\n",
      "\rWarmup:  55%|    | 423/768 [01:10,  7.73it/s, step size=2.25e-01, acc. prob=0.782]\n",
      "\rWarmup:  55%|    | 425/768 [01:10,  7.51it/s, step size=3.00e-01, acc. prob=0.783]\n",
      "\rWarmup:  55%|    | 426/768 [01:10,  6.91it/s, step size=2.53e-01, acc. prob=0.783]\n",
      "\rWarmup:  56%|    | 427/768 [01:11,  6.46it/s, step size=3.30e-01, acc. prob=0.783]\n",
      "\rWarmup:  56%|    | 429/768 [01:11,  8.31it/s, step size=3.31e-01, acc. prob=0.783]\n",
      "\rWarmup:  56%|    | 430/768 [01:11,  7.40it/s, step size=2.79e-01, acc. prob=0.783]\n",
      "\rWarmup:  56%|    | 431/768 [01:11,  6.77it/s, step size=3.37e-01, acc. prob=0.783]\n",
      "\rWarmup:  56%|    | 432/768 [01:11,  6.34it/s, step size=4.47e-01, acc. prob=0.784]\n",
      "\rWarmup:  56%|    | 433/768 [01:12,  6.04it/s, step size=2.45e-01, acc. prob=0.783]\n",
      "\rWarmup:  57%|    | 434/768 [01:12,  5.84it/s, step size=2.78e-01, acc. prob=0.783]\n",
      "\rWarmup:  57%|    | 436/768 [01:12,  7.33it/s, step size=4.32e-01, acc. prob=0.784]\n",
      "\rWarmup:  57%|    | 438/768 [01:12,  7.30it/s, step size=1.98e-01, acc. prob=0.783]\n",
      "\rWarmup:  57%|    | 439/768 [01:12,  7.10it/s, step size=2.62e-01, acc. prob=0.783]\n",
      "\rWarmup:  57%|    | 441/768 [01:12,  8.60it/s, step size=2.95e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 443/768 [01:13,  7.59it/s, step size=1.88e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 444/768 [01:13,  6.65it/s, step size=2.49e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 445/768 [01:13,  5.95it/s, step size=2.57e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 446/768 [01:13,  5.52it/s, step size=1.71e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 447/768 [01:14,  5.22it/s, step size=2.11e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 448/768 [01:14,  5.00it/s, step size=2.41e-01, acc. prob=0.783]\n",
      "\rWarmup:  58%|    | 449/768 [01:14,  5.71it/s, step size=2.79e-01, acc. prob=0.783]\n",
      "\rWarmup:  59%|    | 450/768 [01:14,  6.37it/s, step size=3.11e-01, acc. prob=0.784]\n",
      "\rWarmup:  59%|    | 451/768 [01:14,  5.68it/s, step size=1.63e-01, acc. prob=0.783]\n",
      "\rWarmup:  59%|    | 452/768 [01:15,  5.27it/s, step size=2.15e-01, acc. prob=0.783]\n",
      "\rWarmup:  59%|    | 453/768 [01:15,  5.02it/s, step size=2.46e-01, acc. prob=0.783]\n",
      "\rWarmup:  59%|    | 454/768 [01:15,  5.77it/s, step size=2.94e-01, acc. prob=0.784]\n",
      "\rWarmup:  59%|    | 455/768 [01:15,  6.46it/s, step size=3.47e-01, acc. prob=0.784]\n",
      "\rWarmup:  59%|    | 456/768 [01:15,  7.05it/s, step size=3.09e-01, acc. prob=0.784]\n",
      "\rWarmup:  60%|    | 457/768 [01:15,  7.58it/s, step size=2.65e-01, acc. prob=0.784]\n",
      "\rWarmup:  60%|    | 458/768 [01:15,  7.22it/s, step size=2.51e-01, acc. prob=0.784]\n",
      "\rWarmup:  60%|    | 459/768 [01:16,  7.01it/s, step size=1.81e-01, acc. prob=0.783]\n",
      "\rWarmup:  60%|    | 460/768 [01:16,  6.84it/s, step size=1.96e-01, acc. prob=0.783]\n",
      "\rWarmup:  60%|    | 461/768 [01:16,  6.55it/s, step size=7.77e-01, acc. prob=0.783]\n",
      "\rWarmup:  61%|    | 465/768 [01:16, 12.95it/s, step size=1.81e-01, acc. prob=0.780]\n",
      "\rWarmup:  61%|    | 467/768 [01:16, 14.10it/s, step size=4.04e-01, acc. prob=0.781]\n",
      "\rWarmup:  61%|    | 470/768 [01:16, 17.20it/s, step size=4.15e-02, acc. prob=0.780]\n",
      "\rWarmup:  61%|   | 472/768 [01:17, 10.61it/s, step size=1.39e-01, acc. prob=0.781]\n",
      "\rWarmup:  62%|   | 474/768 [01:17, 11.46it/s, step size=4.78e-01, acc. prob=0.782]\n",
      "\rWarmup:  62%|   | 476/768 [01:17, 10.86it/s, step size=1.55e-01, acc. prob=0.781]\n",
      "\rWarmup:  62%|   | 478/768 [01:17, 11.72it/s, step size=6.61e-02, acc. prob=0.781]\n",
      "\rWarmup:  62%|   | 480/768 [01:17,  9.13it/s, step size=1.82e-01, acc. prob=0.781]\n",
      "\rWarmup:  63%|   | 482/768 [01:18,  9.87it/s, step size=5.35e-01, acc. prob=0.782]\n",
      "\rWarmup:  63%|   | 484/768 [01:18, 11.45it/s, step size=2.22e-01, acc. prob=0.781]\n",
      "\rWarmup:  63%|   | 486/768 [01:18, 11.67it/s, step size=4.37e-01, acc. prob=0.782]\n",
      "\rWarmup:  64%|   | 489/768 [01:18, 10.93it/s, step size=2.15e-01, acc. prob=0.782]\n",
      "\rWarmup:  64%|   | 491/768 [01:18, 11.24it/s, step size=3.84e-01, acc. prob=0.782]\n",
      "\rWarmup:  64%|   | 494/768 [01:18, 14.15it/s, step size=7.27e-02, acc. prob=0.781]\n",
      "\rWarmup:  65%|   | 496/768 [01:19, 12.22it/s, step size=1.64e-01, acc. prob=0.781]\n",
      "\rWarmup:  65%|   | 498/768 [01:19, 13.33it/s, step size=2.96e-01, acc. prob=0.782]\n",
      "\rWarmup:  65%|   | 500/768 [01:19, 12.45it/s, step size=1.60e-01, acc. prob=0.781]\n",
      "\rWarmup:  65%|   | 502/768 [01:19, 13.58it/s, step size=6.46e-02, acc. prob=0.781]\n",
      "\rWarmup:  66%|   | 504/768 [01:19,  9.80it/s, step size=1.64e-01, acc. prob=0.782]\n",
      "\rWarmup:  66%|   | 506/768 [01:20, 10.76it/s, step size=3.28e-01, acc. prob=0.782]\n",
      "\rWarmup:  66%|   | 509/768 [01:20, 11.10it/s, step size=1.29e-01, acc. prob=0.781]\n",
      "\rWarmup:  67%|   | 511/768 [01:20, 10.98it/s, step size=1.91e-01, acc. prob=0.781]\n",
      "\rWarmup:  67%|   | 513/768 [01:20, 10.89it/s, step size=1.91e-01, acc. prob=0.808]\n",
      "\rSample:  67%|   | 515/768 [01:20, 10.82it/s, step size=1.91e-01, acc. prob=0.711]\n",
      "\rSample:  67%|   | 517/768 [01:21, 10.77it/s, step size=1.91e-01, acc. prob=0.821]\n",
      "\rSample:  68%|   | 519/768 [01:21, 10.74it/s, step size=1.91e-01, acc. prob=0.868]\n",
      "\rSample:  68%|   | 521/768 [01:21, 10.72it/s, step size=1.91e-01, acc. prob=0.850]\n",
      "\rSample:  68%|   | 523/768 [01:21, 10.70it/s, step size=1.91e-01, acc. prob=0.833]\n",
      "\rSample:  68%|   | 525/768 [01:21, 10.69it/s, step size=1.91e-01, acc. prob=0.802]\n",
      "\rSample:  69%|   | 528/768 [01:22, 12.33it/s, step size=1.91e-01, acc. prob=0.785]\n",
      "\rSample:  69%|   | 530/768 [01:22, 12.81it/s, step size=1.91e-01, acc. prob=0.806]\n",
      "\rSample:  69%|   | 532/768 [01:22, 12.13it/s, step size=1.91e-01, acc. prob=0.814]\n",
      "\rSample:  70%|   | 534/768 [01:22, 11.69it/s, step size=1.91e-01, acc. prob=0.826]\n",
      "\rSample:  70%|   | 536/768 [01:22, 11.38it/s, step size=1.91e-01, acc. prob=0.840]\n",
      "\rSample:  70%|   | 538/768 [01:22, 12.10it/s, step size=1.91e-01, acc. prob=0.849]\n",
      "\rSample:  70%|   | 540/768 [01:23, 11.64it/s, step size=1.91e-01, acc. prob=0.859]\n",
      "\rSample:  71%|   | 542/768 [01:23, 11.35it/s, step size=1.91e-01, acc. prob=0.866]\n",
      "\rSample:  71%|   | 544/768 [01:23, 11.14it/s, step size=1.91e-01, acc. prob=0.872]\n",
      "\rSample:  71%|   | 546/768 [01:23, 11.91it/s, step size=1.91e-01, acc. prob=0.878]\n",
      "\rSample:  71%|  | 548/768 [01:23, 11.49it/s, step size=1.91e-01, acc. prob=0.883]\n",
      "\rSample:  72%|  | 550/768 [01:23, 11.24it/s, step size=1.91e-01, acc. prob=0.874]\n",
      "\rSample:  72%|  | 552/768 [01:24, 11.06it/s, step size=1.91e-01, acc. prob=0.879]\n",
      "\rSample:  72%|  | 554/768 [01:24, 11.03it/s, step size=1.91e-01, acc. prob=0.883]\n",
      "\rSample:  72%|  | 556/768 [01:24, 11.64it/s, step size=1.91e-01, acc. prob=0.888]\n",
      "\rSample:  73%|  | 558/768 [01:24, 12.11it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  73%|  | 560/768 [01:24, 13.37it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  73%|  | 562/768 [01:24, 13.20it/s, step size=1.91e-01, acc. prob=0.889]\n",
      "\rSample:  73%|  | 564/768 [01:25, 13.26it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  74%|  | 566/768 [01:25, 13.27it/s, step size=1.91e-01, acc. prob=0.887]\n",
      "\rSample:  74%|  | 568/768 [01:25, 12.29it/s, step size=1.91e-01, acc. prob=0.885]\n",
      "\rSample:  74%|  | 570/768 [01:25, 11.73it/s, step size=1.91e-01, acc. prob=0.884]\n",
      "\rSample:  74%|  | 572/768 [01:25, 11.37it/s, step size=1.91e-01, acc. prob=0.869]\n",
      "\rSample:  75%|  | 574/768 [01:25, 12.10it/s, step size=1.91e-01, acc. prob=0.870]\n",
      "\rSample:  75%|  | 576/768 [01:26, 11.61it/s, step size=1.91e-01, acc. prob=0.872]\n",
      "\rSample:  75%|  | 578/768 [01:26, 11.29it/s, step size=1.91e-01, acc. prob=0.873]\n",
      "\rSample:  76%|  | 580/768 [01:26, 11.06it/s, step size=1.91e-01, acc. prob=0.875]\n",
      "\rSample:  76%|  | 582/768 [01:26, 10.93it/s, step size=1.91e-01, acc. prob=0.878]\n",
      "\rSample:  76%|  | 584/768 [01:26, 11.74it/s, step size=1.91e-01, acc. prob=0.880]\n",
      "\rSample:  76%|  | 586/768 [01:26, 12.38it/s, step size=1.91e-01, acc. prob=0.878]\n",
      "\rSample:  77%|  | 588/768 [01:27, 11.80it/s, step size=1.91e-01, acc. prob=0.881]\n",
      "\rSample:  77%|  | 590/768 [01:27, 11.40it/s, step size=1.91e-01, acc. prob=0.879]\n",
      "\rSample:  77%|  | 592/768 [01:27, 11.15it/s, step size=1.91e-01, acc. prob=0.881]\n",
      "\rSample:  77%|  | 594/768 [01:27, 11.91it/s, step size=1.91e-01, acc. prob=0.882]\n",
      "\rSample:  78%|  | 596/768 [01:27, 11.48it/s, step size=1.91e-01, acc. prob=0.884]\n",
      "\rSample:  78%|  | 598/768 [01:27, 11.20it/s, step size=1.91e-01, acc. prob=0.886]\n",
      "\rSample:  78%|  | 600/768 [01:28, 11.02it/s, step size=1.91e-01, acc. prob=0.888]\n",
      "\rSample:  78%|  | 602/768 [01:28, 11.81it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  79%|  | 604/768 [01:28, 12.44it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  79%|  | 606/768 [01:28, 11.83it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  79%|  | 608/768 [01:28, 11.43it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  79%|  | 610/768 [01:29, 11.16it/s, step size=1.91e-01, acc. prob=0.894]\n",
      "\rSample:  80%|  | 612/768 [01:29, 10.99it/s, step size=1.91e-01, acc. prob=0.895]\n",
      "\rSample:  80%|  | 614/768 [01:29, 10.87it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample:  80%|  | 616/768 [01:29,  9.43it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample:  80%|  | 617/768 [01:29,  9.35it/s, step size=1.91e-01, acc. prob=0.897]\n",
      "\rSample:  80%|  | 618/768 [01:29,  9.20it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  81%|  | 620/768 [01:30, 10.12it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  81%|  | 622/768 [01:30,  9.76it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  81%|  | 623/768 [01:30,  9.62it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  81%| | 624/768 [01:30,  9.47it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  81%| | 625/768 [01:30,  9.37it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  82%| | 626/768 [01:30,  9.19it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  82%| | 628/768 [01:30, 10.19it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  82%| | 629/768 [01:31,  9.89it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  82%| | 631/768 [01:31, 10.11it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  83%| | 634/768 [01:31, 12.17it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  83%| | 636/768 [01:31, 11.65it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  83%| | 638/768 [01:31, 11.32it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  83%| | 640/768 [01:31, 11.09it/s, step size=1.91e-01, acc. prob=0.902]\n",
      "\rSample:  84%| | 642/768 [01:32, 10.94it/s, step size=1.91e-01, acc. prob=0.903]\n",
      "\rSample:  84%| | 644/768 [01:32, 10.81it/s, step size=1.91e-01, acc. prob=0.903]\n",
      "\rSample:  84%| | 646/768 [01:32, 10.70it/s, step size=1.91e-01, acc. prob=0.904]\n",
      "\rSample:  84%| | 648/768 [01:32, 10.67it/s, step size=1.91e-01, acc. prob=0.906]\n",
      "\rSample:  85%| | 650/768 [01:32, 10.65it/s, step size=1.91e-01, acc. prob=0.907]\n",
      "\rSample:  85%| | 652/768 [01:33, 10.64it/s, step size=1.91e-01, acc. prob=0.905]\n",
      "\rSample:  85%| | 654/768 [01:33, 10.63it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  85%| | 656/768 [01:33, 10.62it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  86%| | 658/768 [01:33, 10.60it/s, step size=1.91e-01, acc. prob=0.893]\n",
      "\rSample:  86%| | 660/768 [01:33, 10.59it/s, step size=1.91e-01, acc. prob=0.894]\n",
      "\rSample:  86%| | 662/768 [01:33, 11.45it/s, step size=1.91e-01, acc. prob=0.894]\n",
      "\rSample:  86%| | 664/768 [01:34, 11.18it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  87%| | 666/768 [01:34, 10.99it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  87%| | 668/768 [01:34, 11.78it/s, step size=1.91e-01, acc. prob=0.887]\n",
      "\rSample:  87%| | 670/768 [01:34, 11.38it/s, step size=1.91e-01, acc. prob=0.888]\n",
      "\rSample:  88%| | 672/768 [01:34, 11.10it/s, step size=1.91e-01, acc. prob=0.889]\n",
      "\rSample:  88%| | 675/768 [01:35, 12.58it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  88%| | 677/768 [01:35, 11.98it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  88%| | 679/768 [01:35, 11.56it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  89%| | 681/768 [01:35, 11.25it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  89%| | 683/768 [01:35, 11.03it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  89%| | 685/768 [01:36, 10.89it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  89%| | 687/768 [01:36, 11.66it/s, step size=1.91e-01, acc. prob=0.893]\n",
      "\rSample:  90%| | 689/768 [01:36, 11.31it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  90%| | 691/768 [01:36, 11.08it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  90%| | 693/768 [01:36, 10.90it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  90%| | 695/768 [01:36, 11.70it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  91%| | 697/768 [01:37, 11.33it/s, step size=1.91e-01, acc. prob=0.890]\n",
      "\rSample:  91%| | 699/768 [01:37, 11.06it/s, step size=1.91e-01, acc. prob=0.891]\n",
      "\rSample:  91%|| 701/768 [01:37, 10.88it/s, step size=1.91e-01, acc. prob=0.892]\n",
      "\rSample:  92%|| 703/768 [01:37, 10.75it/s, step size=1.91e-01, acc. prob=0.893]\n",
      "\rSample:  92%|| 705/768 [01:37, 11.44it/s, step size=1.91e-01, acc. prob=0.894]\n",
      "\rSample:  92%|| 708/768 [01:37, 12.85it/s, step size=1.91e-01, acc. prob=0.894]\n",
      "\rSample:  92%|| 710/768 [01:38, 12.14it/s, step size=1.91e-01, acc. prob=0.895]\n",
      "\rSample:  93%|| 712/768 [01:38, 12.65it/s, step size=1.91e-01, acc. prob=0.895]\n",
      "\rSample:  93%|| 714/768 [01:38, 11.97it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample:  93%|| 716/768 [01:38, 11.51it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample:  93%|| 718/768 [01:38, 12.17it/s, step size=1.91e-01, acc. prob=0.897]\n",
      "\rSample:  94%|| 720/768 [01:39, 11.63it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  94%|| 722/768 [01:39, 11.30it/s, step size=1.91e-01, acc. prob=0.895]\n",
      "\rSample:  94%|| 724/768 [01:39, 11.07it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample:  95%|| 726/768 [01:39, 10.91it/s, step size=1.91e-01, acc. prob=0.897]\n",
      "\rSample:  95%|| 728/768 [01:39, 11.69it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  95%|| 730/768 [01:39, 11.31it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  95%|| 732/768 [01:40, 11.06it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  96%|| 734/768 [01:40, 10.92it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  96%|| 736/768 [01:40, 10.80it/s, step size=1.91e-01, acc. prob=0.898]\n",
      "\rSample:  96%|| 738/768 [01:40, 10.70it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  96%|| 740/768 [01:40, 11.53it/s, step size=1.91e-01, acc. prob=0.899]\n",
      "\rSample:  97%|| 742/768 [01:41, 11.22it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  97%|| 744/768 [01:41, 11.02it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  97%|| 746/768 [01:41, 11.81it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  97%|| 748/768 [01:41, 12.15it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  98%|| 750/768 [01:41, 12.36it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  98%|| 752/768 [01:41, 12.56it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  98%|| 754/768 [01:41, 12.72it/s, step size=1.91e-01, acc. prob=0.901]\n",
      "\rSample:  98%|| 756/768 [01:42, 12.85it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  99%|| 758/768 [01:42, 12.84it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  99%|| 760/768 [01:42, 12.69it/s, step size=1.91e-01, acc. prob=0.900]\n",
      "\rSample:  99%|| 762/768 [01:42, 12.69it/s, step size=1.91e-01, acc. prob=0.897]\n",
      "\rSample:  99%|| 764/768 [01:42, 12.70it/s, step size=1.91e-01, acc. prob=0.897]\n",
      "\rSample: 100%|| 766/768 [01:42, 13.76it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample: 100%|| 768/768 [01:43, 13.19it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\rSample: 100%|| 768/768 [01:43,  7.45it/s, step size=1.91e-01, acc. prob=0.896]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "borehole_res = eval_models_on_problem(problem, train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "customInput": null,
    "executionStartTime": 1743529103501,
    "executionStopTime": 1743529104461,
    "language": "python",
    "originalKey": "f2fc99ee-52d0-420f-8f1a-0f1293689aad",
    "output": {
     "id": "660736130231383"
    },
    "outputsInitialized": true,
    "requestMsgId": "76d49bc3-3046-4c1a-8538-bd0190d04489",
    "serverExecutionDuration": 3.7160157226026,
    "showInput": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'STGP - target only': {'NLL': 820.1311610482774, 'MSE': 1658.1030020306143},\n",
       " 'MTGP - ICM - MAP': {'NLL': 298.84299270373793, 'MSE': 11.273867204848827},\n",
       " 'MTGP - Latent Embeddings - FB': {'NLL': 525.3912920530319,\n",
       "  'MSE': 20.109351468055014},\n",
       " 'MTGP - Latent Embeddings - MAP': {'NLL': 438.331706460182,\n",
       "  'MSE': 53.53423246625931}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "borehole_res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "customInput": null,
    "language": "python",
    "originalKey": "471f2a59-d882-46f1-b8d5-2cd3575a9399",
    "showInput": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "pfn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "last_base_url": "https://bento.edge.x2p.facebook.net/",
  "last_kernel_id": "a682d8c7-e233-4792-8769-ce2b92d6bc01",
  "last_msg_id": "cbc97cad-5a66beaedc4295bba571018a_4963",
  "last_server_session_id": "9609c3ef-402e-4a60-9386-29209d9ba159"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
